import os
import json
import numpy as np
import glob
from tqdm import tqdm
try:
    from pycocotools import mask as coco_mask
except ImportError:
    print("Please install pycocotools: pip install pycocotools")

def calculate_dataset_stats(data_dir):
    print(f"ğŸ” Scanning dataset in: {data_dir} ...")
    
    # æŸ¥æ‰¾æ‰€æœ‰ json æ–‡ä»¶
    json_paths = glob.glob(os.path.join(data_dir, "**", "*.json"), recursive=True)
    
    all_areas = []
    
    print(f"Found {len(json_paths)} json files. Calculating areas...")
    
    for json_path in tqdm(json_paths):
        try:
            with open(json_path, 'r') as f:
                data = json.load(f)
            
            # å…¼å®¹ SA-1B æ ¼å¼ (dict with 'annotations' key or list)
            annotations = data.get('annotations', []) if isinstance(data, dict) else data
            
            for ann in annotations:
                area = 0
                # ä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—çš„ area å­—æ®µ
                if 'area' in ann:
                    area = ann['area']
                # å¦‚æœæ²¡æœ‰ï¼Œä» segmentation è®¡ç®—
                elif 'segmentation' in ann:
                    seg = ann['segmentation']
                    if isinstance(seg, dict) and 'counts' in seg: # RLE
                        area = int(coco_mask.area(seg))
                    elif isinstance(seg, list): # Polygon
                        # Polygon area calculation implies decoding or shapely, 
                        # for simplicity we assume area field exists or skip complex poly calc here
                        pass 
                
                if area > 0:
                    all_areas.append(area)
                    
        except Exception as e:
            print(f"Error processing {json_path}: {e}")
            continue

    if not all_areas:
        print("âŒ No nuclei found! Check your data path or json format.")
        return None

    # === æ ¸å¿ƒç»Ÿè®¡å­¦è®¡ç®— ===
    all_areas = np.array(all_areas)
    mean_area = np.mean(all_areas)
    std_area = np.std(all_areas)
    
    # PromptNu è®ºæ–‡å®šä¹‰:
    # Small < Mean
    # Large > Mean + 2 * Std
    
    stats = {
        "count": len(all_areas),
        "mean_area": float(mean_area),
        "std_area": float(std_area),
        "thresholds": {
            "small_upper": float(mean_area),               # å°äºå‡å€¼ç®— Small
            "large_lower": float(mean_area + 2 * std_area) # å¤§äº å‡å€¼+2å€æ–¹å·® ç®— Large
        }
    }
    
    print("\nâœ… Statistics Calculated:")
    print(f"   Total Nuclei: {stats['count']}")
    print(f"   Mean Area (Î¼): {stats['mean_area']:.2f}")
    print(f"   Std Dev (Ïƒ):   {stats['std_area']:.2f}")
    print(f"   --------------------------------")
    print(f"   [Small]  < {stats['thresholds']['small_upper']:.2f} pixels")
    print(f"   [Medium] {stats['thresholds']['small_upper']:.2f} ~ {stats['thresholds']['large_lower']:.2f} pixels")
    print(f"   [Large]  > {stats['thresholds']['large_lower']:.2f} pixels")
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    save_path = os.path.join(data_dir, "dataset_stats.json")
    with open(save_path, 'w') as f:
        json.dump(stats, f, indent=4)
    print(f"\nğŸ’¾ Stats saved to: {save_path}")
    return stats

if __name__ == "__main__":
    # è¯·ä¿®æ”¹ä¸ºæ‚¨å®é™…çš„æ•°æ®è·¯å¾„
    DATA_PATH = "data/MoNuSeg_SA1B" 
    calculate_dataset_stats(DATA_PATH)