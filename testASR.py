import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from segment_anything import sam_model_registry
from segment_anything.modeling.sam import TextSam
import os
import json

# === ğŸ”§ é…ç½®åŒºåŸŸ ===
# 1. æ‚¨çš„æ¨¡å‹æƒé‡è·¯å¾„
CHECKPOINT_PATH = "workdir/models/MP_SAM_End2End/best_model.pth" 

# 2. æ‚¨çš„æµ‹è¯•å›¾ç‰‡è·¯å¾„ (è¯·ç¡®ä¿å¯¹åº”çš„ .json æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹ï¼Œæˆ–è€…åœ¨ labels ç›®å½•ä¸‹)
IMAGE_PATH = "data/PanNuke_SA1B/test/sa_0007543.png" 

# 3. è®¾å¤‡
DEVICE = "cuda"

# === ğŸ§  æ ¸å¿ƒå‡½æ•°ï¼šåŠ è½½ SA-1B æ ¼å¼çœŸå€¼ ===
def load_data_from_json(img_path):
    """
    æ ¹æ®å›¾ç‰‡è·¯å¾„å¯»æ‰¾å¹¶è§£æ SA-1B æ ¼å¼çš„ JSON
    è¿”å›: (gt_mask, organ_name)
    """
    # 1. æ¨æ–­ JSON è·¯å¾„
    # ç­–ç•¥ A: åŒå json (sa_0007543.png -> sa_0007543.json)
    json_path = os.path.splitext(img_path)[0] + ".json"
    
    # ç­–ç•¥ B: å¦‚æœä¸åœ¨åŒçº§ç›®å½•ï¼Œå¯èƒ½åœ¨ä¸Šä¸€çº§çš„ labels ç›®å½• (æ ¹æ®æ‚¨çš„æ•°æ®é›†ç»“æ„è°ƒæ•´)
    if not os.path.exists(json_path):
        # å°è¯•æŠŠè·¯å¾„ä¸­çš„ /Images/ æ›¿æ¢ä¸º /Labels/ æˆ– /Jsons/
        # è¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„çŒœæµ‹ï¼Œå¦‚æœæ‚¨çš„ json å’Œ png éƒ½åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œä¸Šé¢çš„ç­–ç•¥ A å°±å¤Ÿäº†
        candidate = img_path.replace("/Images/", "/Labels/").replace(".png", ".json")
        if os.path.exists(candidate):
            json_path = candidate

    if not os.path.exists(json_path):
        print(f"âš ï¸ æœªæ‰¾åˆ° JSON æ–‡ä»¶: {json_path}")
        return None, "Generic"

    # 2. è§£æ JSON
    try:
        with open(json_path, 'r') as f:
            data = json.load(f)
            
        # è·å–å›¾ç‰‡å°ºå¯¸
        h = data.get('height', 256)
        w = data.get('width', 256)
        
        # è·å–å™¨å®˜ç±»å‹ (è‡ªåŠ¨æ¨æ–­ Prompt!)
        organ_type = data.get('organ_type', 'Generic')
        
        # ç»˜åˆ¶ Mask
        mask = np.zeros((h, w), dtype=np.uint8)
        annotations = data.get('annotations', [])
        
        for ann in annotations:
            seg = ann.get('segmentation', [])
            # å¤„ç† Polygon æ ¼å¼: [[x1, y1, x2, y2, ...]]
            for poly in seg:
                # å°†æ‰å¹³åˆ—è¡¨è½¬ä¸º (N, 2) åæ ‡ç‚¹
                pts = np.array(poly, dtype=np.int32).reshape((-1, 2))
                cv2.fillPoly(mask, [pts], 1)
                
        return mask, organ_type

    except Exception as e:
        print(f"âŒ JSON è§£æé”™è¯¯: {e}")
        return None, "Generic"

# === ğŸª Hook å‡½æ•°ï¼šå·çª¥ ASR å†…éƒ¨ ===
activation = {}
def get_activation(name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook

def main():
    # 1. å‡†å¤‡å‚æ•° (Args)
    # ç¡®ä¿è¿™é‡Œçš„ image_size ä¸è®­ç»ƒæ—¶ä¸€è‡´
    args = type('Args', (), {
        'image_size': 512, 
        'crop_size': 256, 
        'num_organs': 21,
        'encoder_adapter': True, 
        'sam_checkpoint': None, 
        'checkpoint': None
    })()
    
    print(f"ğŸš€ å¼€å§‹éªŒè¯: {IMAGE_PATH}")

    # 2. åŠ è½½æ•°æ®ä¸çœŸå€¼
    image = cv2.imread(IMAGE_PATH)
    if image is None:
        print("âŒ å›¾ç‰‡è¯»å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
        return

    # è·å– GT å’Œ å™¨å®˜ç±»å‹
    gt_mask, organ_name = load_data_from_json(IMAGE_PATH)
    print(f"ğŸ“‹ è‡ªåŠ¨è¯†åˆ«å™¨å®˜: {organ_name}")
    
    # é¢„å¤„ç†å›¾ç‰‡
    image_input = cv2.resize(image, (512, 512))
    img_tensor = torch.from_numpy(image_input).permute(2, 0, 1).float().to(DEVICE).unsqueeze(0)
    
    # é¢„å¤„ç† GT (ç”¨äºå¯è§†åŒ–)
    if gt_mask is not None:
        gt_mask = cv2.resize(gt_mask, (512, 512), interpolation=cv2.INTER_NEAREST)

    # 3. æ„å»ºæ¨¡å‹
    vanilla_sam = sam_model_registry["vit_b"](args)
    model = TextSam(
        image_encoder=vanilla_sam.image_encoder,
        prompt_encoder=vanilla_sam.prompt_encoder,
        mask_decoder=vanilla_sam.mask_decoder,
        num_organs=21
    ).to(DEVICE)
    
    # åŠ è½½æƒé‡
    if os.path.exists(CHECKPOINT_PATH):
        ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)
        model.load_state_dict(ckpt, strict=False)
        print("âœ… æƒé‡åŠ è½½æˆåŠŸ")
    else:
        print(f"âŒ æƒé‡æœªæ‰¾åˆ°: {CHECKPOINT_PATH}")
        return
        
    model.eval()

    # 4. æ³¨å†Œ ASR æ¢é’ˆ
    # æ³¨æ„: è·¯å¾„å¯èƒ½æ ¹æ®æ‚¨çš„ä»£ç å¾®è°ƒï¼Œé€šå¸¸æ˜¯ model.mask_decoder.asr_upscale_1.gate[1]
    if hasattr(model.mask_decoder, 'asr_upscale_1'):
        model.mask_decoder.asr_upscale_1.gate[1].register_forward_hook(get_activation('asr_gate'))
        print("ğŸª å·²æŒ‚è½½ ASR Gate æ¢é’ˆ")

    # 5. æ„é€  Input (è‡ªåŠ¨ä½¿ç”¨ JSON é‡Œçš„å™¨å®˜å)
    # ç®€å•çš„ Organ ID æ˜ å°„ (æ ¹æ®æ‚¨çš„ ID_TO_ORGAN å­—å…¸)
    ORGAN_TO_ID = {
        "Kidney": 0, "Breast": 1, "Prostate": 2, "Lung": 3, 
        "Colon": 4, "Stomach": 5, "Liver": 6, "Bladder": 7, 
        "Brain": 8, "Generic": 9
    }
    organ_id = ORGAN_TO_ID.get(organ_name, 9) # é»˜è®¤ä¸º Generic

    input_sample = [{
        'image': img_tensor.squeeze(0),
        'original_size': (512, 512),
        'text_prompt': f"{organ_name} cell nuclei", # è‡ªåŠ¨ç”Ÿæˆ Prompt
        'organ_id': organ_id,
        'attribute_text': f"{organ_name} cell nuclei"
    }]

    # 6. æ¨ç†
    with torch.no_grad():
        outputs = model(input_sample, multimask_output=True)
    
    # 7. æå–ç»“æœ
    res = outputs[0]
    # å–æœ€é«˜åˆ†çš„ Mask
    best_idx = torch.argmax(res['iou_predictions'])
    pred_mask = res['masks'][0, best_idx].cpu().numpy()
    
    # æå– SAR Density Map
    density_map = res.get('density_map', torch.zeros(1, 512, 512)).squeeze().cpu().numpy()
    
    # æå– ASR Gate Map
    gate_map = activation.get('asr_gate', torch.zeros(1, 1, 512, 512))
    gate_map = gate_map.mean(dim=0).squeeze().cpu().numpy() # [H, W]
    gate_map = cv2.resize(gate_map, (512, 512))

    # 8. ç»˜å›¾ (äº”è”å›¾ï¼šåŸå›¾ - GT - é¢„æµ‹ - è¯­ä¹‰ - é—¨æ§)
    plt.figure(figsize=(25, 5))
    
    # A. åŸå›¾
    plt.subplot(1, 5, 1)
    plt.title(f"Image ({organ_name})")
    plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))
    plt.axis('off')

    # B. Ground Truth (çœŸå€¼)
    plt.subplot(1, 5, 2)
    plt.title("Ground Truth")
    if gt_mask is not None:
        plt.imshow(gt_mask, cmap='gray')
    else:
        plt.text(0.5, 0.5, "GT Not Found", ha='center')
    plt.axis('off')

    # C. Prediction (é¢„æµ‹)
    plt.subplot(1, 5, 3)
    plt.title("Prediction")
    plt.imshow(pred_mask > 0, cmap='gray')
    plt.axis('off')

    # D. SAR Density (ä½ çš„â€œå­¦éœ¸â€æŒ‡æŒ¥å®˜)
    plt.subplot(1, 5, 4)
    plt.title("SAR Density (Semantic)")
    plt.imshow(density_map, cmap='jet') # çº¢=é«˜å¯†åº¦, è“=ä½å¯†åº¦
    plt.axis('off')

    # E. ASR Gate (ä½ çš„â€œå­¦æ¸£â€æ‰§è¡Œå™¨)
    plt.subplot(1, 5, 5)
    plt.title("ASR Gate (Current State)")
    plt.imshow(gate_map, cmap='magma') # äº®=é«˜é¢‘æ³¨å…¥, æš—=å¹³æ»‘
    plt.axis('off')

    save_path = "verification_final.png"
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    print(f"\nğŸ“¸ éªŒè¯å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {save_path}")
    print("ğŸ‘‰ è¯·é‡ç‚¹å¯¹æ¯” [Ground Truth] vs [ASR Gate] ä»¥åŠ [SAR Density] vs [ASR Gate]")

if __name__ == "__main__":
    main()