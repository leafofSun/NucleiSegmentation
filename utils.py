from albumentations.pytorch import ToTensorV2
import cv2
import albumentations as A
import torch
import numpy as np
from torch.nn import functional as F
from skimage.measure import label, regionprops
from matplotlib import pyplot as plt
import random
import torch.nn as nn
import logging
import os

# ==========================================
# è¾…åŠ©å‡½æ•°éƒ¨åˆ†
# ==========================================

def get_boxes_from_mask(mask, box_num=1, std=0.1, max_pixel=5):
    """
    ä» mask ä¸­æå–è¾¹ç•Œæ¡†ï¼Œæ”¯æŒç©º mask çš„å¥å£®å¤„ç†
    """
    if isinstance(mask, torch.Tensor):
        mask = mask.numpy()

    # å¦‚æœ mask åŒ…å« 255 (Ignore)ï¼Œæˆ‘ä»¬åœ¨ç”Ÿæˆ Box æ—¶åªçœ‹ 1 (Target)
    mask_for_box = np.zeros_like(mask)
    mask_for_box[mask == 1] = 1
    
    if mask_for_box.max() > 0:
        label_img = label(mask_for_box)
    else:
        return torch.tensor([[0, 0, 1, 1]] * box_num, dtype=torch.float)
        
    regions = regionprops(label_img)
    boxes = [tuple(region.bbox) for region in regions]

    if len(boxes) == 0:
        return torch.tensor([[0, 0, 1, 1]] * box_num, dtype=torch.float)

    if len(boxes) >= box_num:
        sorted_regions = sorted(regions, key=lambda x: x.area, reverse=True)[:box_num]
        boxes = [tuple(region.bbox) for region in sorted_regions]

    elif len(boxes) < box_num:
        num_duplicates = box_num - len(boxes)
        boxes += [boxes[i % len(boxes)] for i in range(num_duplicates)]

    noise_boxes = []
    for box in boxes:
        y0, x0, y1, x1 = box
        width, height = abs(x1 - x0), abs(y1 - y0)
        noise_std = min(width, height) * std
        max_noise = min(max_pixel, int(noise_std * 5))
        try:
            noise_x = np.random.randint(-max_noise, max_noise)
        except:
            noise_x = 0
        try:
            noise_y = np.random.randint(-max_noise, max_noise)
        except:
            noise_y = 0
        x0, y0 = x0 + noise_x, y0 + noise_y
        x1, y1 = x1 + noise_x, y1 + noise_y
        noise_boxes.append((x0, y0, x1, y1))
        
    return torch.as_tensor(noise_boxes, dtype=torch.float)


def select_random_points(pr, gt, point_num = 9):
    pred, gt = pr.data.cpu().numpy(), gt.data.cpu().numpy()
    error = np.zeros_like(pred)
    
    # åªåœ¨æ˜ç¡®çš„ 0/1 åŒºåŸŸè®¡ç®— Errorï¼Œå¿½ç•¥ 255
    valid_mask = (gt != 255)
    error[(pred != gt) & valid_mask] = 1

    batch_points = []
    batch_labels = []
    for j in range(error.shape[0]):
        one_pred = pred[j].squeeze(0)
        one_gt = gt[j].squeeze(0)
        one_erroer = error[j].squeeze(0)

        indices = np.argwhere(one_erroer == 1)
        if indices.shape[0] > 0:
            selected_indices = indices[np.random.choice(indices.shape[0], point_num, replace=True)]
        else:
            h, w = one_pred.shape
            indices = np.random.randint(0, min(h, w), size=(point_num, 2))
            selected_indices = indices
            
        selected_indices = selected_indices.reshape(-1, 2)

        points, labels = [], []
        for i in selected_indices:
            x, y = i[0], i[1]
            if one_gt[x,y] == 1:
                label = 1
            elif one_gt[x,y] == 0:
                label = 0
            else:
                label = -1 
            points.append((y, x))
            labels.append(label)

        batch_points.append(points)
        batch_labels.append(labels)
    return np.array(batch_points), np.array(batch_labels)


def init_point_sampling(mask, get_point=1):
    if isinstance(mask, torch.Tensor):
        mask = mask.numpy()
        
    fg_coords = np.argwhere(mask == 1)[:,::-1]
    bg_coords = np.argwhere(mask == 0)[:,::-1]

    fg_size = len(fg_coords)
    bg_size = len(bg_coords)

    if get_point == 1:
        if fg_size > 0:
            index = np.random.randint(fg_size)
            fg_coord = fg_coords[index]
            label = 1
        else:
            index = np.random.randint(bg_size)
            fg_coord = bg_coords[index]
            label = 0
        return torch.as_tensor([fg_coord.tolist()], dtype=torch.float), torch.as_tensor([label], dtype=torch.int)
    else:
        num_fg = get_point // 2
        num_bg = get_point - num_fg
        if fg_size > 0:
            fg_indices = np.random.choice(fg_size, size=num_fg, replace=True)
            fg_coords_sel = fg_coords[fg_indices]
            fg_labels = np.ones(num_fg)
        else:
            fg_coords_sel = np.empty((0, 2))
            fg_labels = np.array([])
            num_bg = get_point

        if bg_size > 0:
            bg_indices = np.random.choice(bg_size, size=num_bg, replace=True)
            bg_coords_sel = bg_coords[bg_indices]
            bg_labels = np.zeros(num_bg)
        else:
            bg_coords_sel = np.empty((0, 2))
            bg_labels = np.array([])

        coords = np.concatenate([fg_coords_sel, bg_coords_sel], axis=0)
        labels = np.concatenate([fg_labels, bg_labels]).astype(int)
        
        if len(coords) < get_point:
             padding = get_point - len(coords)
             coords = np.pad(coords, ((0, padding), (0, 0)), mode='edge')
             labels = np.pad(labels, (0, padding), mode='edge')

        indices = np.random.permutation(len(coords))
        coords, labels = torch.as_tensor(coords[indices], dtype=torch.float), torch.as_tensor(labels[indices], dtype=torch.int)
        return coords, labels
    

def get_transforms(img_size, ori_h, ori_w, mode='train'):
    transforms = []
    if mode == 'train':
        if ori_h < img_size or ori_w < img_size:
            transforms.append(A.PadIfNeeded(
                min_height=img_size, 
                min_width=img_size, 
                border_mode=cv2.BORDER_CONSTANT, 
                fill=0, 
                fill_mask=0
            ))
        transforms.append(A.RandomCrop(height=img_size, width=img_size))
    elif mode == 'test':
        transforms.append(A.PadIfNeeded(
            min_height=img_size, 
            min_width=img_size, 
            border_mode=cv2.BORDER_CONSTANT, 
            fill=0, 
            fill_mask=0
        ))
    transforms.append(ToTensorV2(p=1.0))
    return A.Compose(transforms, p=1.)


def train_transforms(img_size, ori_h, ori_w):
    return get_transforms(img_size, ori_h, ori_w, mode='train')


def get_logger(filename, verbosity=1, name=None):
    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}
    formatter = logging.Formatter(
        "[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s"
    )
    logger = logging.getLogger(name)
    logger.setLevel(level_dict[verbosity])

    os.makedirs(os.path.dirname(filename), exist_ok=True)

    fh = logging.FileHandler(filename, "w")
    fh.setFormatter(formatter)
    logger.addHandler(fh)

    sh = logging.StreamHandler()
    sh.setFormatter(formatter)
    logger.addHandler(sh)

    return logger


def generate_point(masks, labels, low_res_masks, batched_input, point_num):
    masks_clone = masks.clone()
    masks_sigmoid = torch.sigmoid(masks_clone)
    masks_binary = (masks_sigmoid > 0.5).float()

    low_res_masks_clone = low_res_masks.clone()
    low_res_masks_logist = torch.sigmoid(low_res_masks_clone)

    points, point_labels = select_random_points(masks_binary, labels, point_num = point_num)
    batched_input["mask_inputs"] = low_res_masks_logist
    batched_input["point_coords"] = torch.as_tensor(points)
    batched_input["point_labels"] = torch.as_tensor(point_labels)
    batched_input["boxes"] = None
    return batched_input


def setting_prompt_none(batched_input):
    batched_input["point_coords"] = None
    batched_input["point_labels"] = None
    batched_input["boxes"] = None
    return batched_input


def draw_boxes(img, boxes):
    img_copy = np.copy(img)
    for box in boxes:
        pt1 = (int(box[0]), int(box[1]))
        pt2 = (int(box[2]), int(box[3]))
        cv2.rectangle(img_copy, pt1, pt2, (0, 255, 0), 2)
    return img_copy


def save_masks(preds, save_path, mask_name, image_size, original_size, pad=None,  boxes=None, points=None, visual_prompt=True):
    ori_h, ori_w = original_size

    preds = torch.sigmoid(preds)
    preds[preds > 0.5] = int(1)
    preds[preds <= 0.5] = int(0)

    mask = preds.squeeze().cpu().numpy()
    
    if mask.shape[0] != ori_h or mask.shape[1] != ori_w:
        mask = cv2.resize(mask, (ori_w, ori_h), interpolation=cv2.INTER_NEAREST)
    
    mask = cv2.cvtColor(mask * 255, cv2.COLOR_GRAY2BGR)

    if visual_prompt: 
        if boxes is not None:
            boxes_np = boxes.cpu().numpy() if isinstance(boxes, torch.Tensor) else boxes
            if boxes_np.ndim == 1:
                boxes_np = boxes_np.reshape(1, -1)
            elif boxes_np.ndim > 2:
                boxes_np = boxes_np.reshape(-1, 4)
            
            boxes_ori = []
            for box in boxes_np:
                x0, y0, x1, y1 = box
                if pad is not None:
                    x0_ori = max(0, int(x0 - pad[1] + 0.5))
                    y0_ori = max(0, int(y0 - pad[0] + 0.5))
                    x1_ori = min(ori_w, int(x1 - pad[1] + 0.5))
                    y1_ori = min(ori_h, int(y1 - pad[0] + 0.5))
                else:
                    x0_ori = int(x0 * ori_w / image_size) 
                    y0_ori = int(y0 * ori_h / image_size) 
                    x1_ori = int(x1 * ori_w / image_size) 
                    y1_ori = int(y1 * ori_h / image_size)
                
                if x1_ori > x0_ori and y1_ori > y0_ori:
                    boxes_ori.append((x0_ori, y0_ori, x1_ori, y1_ori))
            
            if boxes_ori:
                mask = draw_boxes(mask, boxes_ori)

        if points is not None:
            point_coords, point_labels = points[0], points[1]
            if isinstance(point_coords, torch.Tensor):
                point_coords = point_coords.squeeze(0).cpu().numpy()
            if isinstance(point_labels, torch.Tensor):
                point_labels = point_labels.squeeze(0).cpu().numpy()
            
            if point_coords.ndim == 1:
                point_coords = point_coords.reshape(1, -1)
            elif point_coords.ndim > 2:
                point_coords = point_coords.reshape(-1, 2)
            
            if point_labels.ndim > 1:
                point_labels = point_labels.flatten()
            
            for (x, y), label in zip(point_coords, point_labels):
                if pad is not None:
                    x_ori = max(0, min(ori_w - 1, int(x - pad[1] + 0.5)))
                    y_ori = max(0, min(ori_h - 1, int(y - pad[0] + 0.5)))
                else:
                    x_ori = max(0, min(ori_w - 1, int(x * ori_w / image_size)))
                    y_ori = max(0, min(ori_h - 1, int(y * ori_h / image_size)))
                
                color = (0, 255, 0) if label == 1 else (0, 0, 255)
                cv2.drawMarker(mask, (int(x_ori), int(y_ori)), color, markerType=cv2.MARKER_CROSS, markerSize=7, thickness=2)  
    
    os.makedirs(save_path, exist_ok=True)
    mask_path = os.path.join(save_path, f"{mask_name}")
    cv2.imwrite(mask_path, np.uint8(mask))


# ==========================================
# Loss Classes
# ==========================================

class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=0.25, ignore_index=255):
        super(FocalLoss, self).__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.ignore_index = ignore_index

    def forward(self, pred, mask):
        assert pred.shape == mask.shape, "pred and mask should have the same shape."
        valid_mask = (mask != self.ignore_index)
        if valid_mask.sum() == 0:
            return pred.sum() * 0.0

        p = torch.sigmoid(pred)[valid_mask]   # [N]
        targets = mask[valid_mask]            # [N]
        
        num_pos = torch.sum(targets)
        num_neg = targets.numel() - num_pos
        
        w_pos = (1 - p) ** self.gamma
        w_neg = p ** self.gamma

        loss_pos = -self.alpha * targets * w_pos * torch.log(p + 1e-12)
        loss_neg = -(1 - self.alpha) * (1 - targets) * w_neg * torch.log(1 - p + 1e-12)

        loss = (torch.sum(loss_pos) + torch.sum(loss_neg)) / (num_pos + num_neg + 1e-12)
        return loss


class DiceLoss(nn.Module):
    def __init__(self, smooth=1.0, ignore_index=255):
        super(DiceLoss, self).__init__()
        self.smooth = smooth
        self.ignore_index = ignore_index

    def forward(self, pred, mask):
        assert pred.shape == mask.shape, "pred and mask should have the same shape."
        valid_mask = (mask != self.ignore_index)
        if valid_mask.sum() == 0:
            return pred.sum() * 0.0

        p = torch.sigmoid(pred)[valid_mask]
        targets = mask[valid_mask]

        intersection = torch.sum(p * targets)
        union = torch.sum(p) + torch.sum(targets)
        dice_loss = (2.0 * intersection + self.smooth) / (union + self.smooth)
        return 1 - dice_loss


class MaskIoULoss(nn.Module):
    def __init__(self, ignore_index=255):
        super(MaskIoULoss, self).__init__()
        self.ignore_index = ignore_index

    def forward(self, pred_mask, ground_truth_mask, pred_iou):
        assert pred_mask.shape == ground_truth_mask.shape
        valid = (ground_truth_mask != self.ignore_index)
        
        p = torch.sigmoid(pred_mask)
        gt = ground_truth_mask.clone()
        
        p = p * valid.float()
        gt = gt * valid.float()
        
        intersection = torch.sum(p * gt, dim=(1, 2, 3))
        union = torch.sum(p, dim=(1, 2, 3)) + torch.sum(gt, dim=(1, 2, 3)) - intersection
        
        gt_iou = (intersection + 1e-7) / (union + 1e-7)
        iou_loss = torch.mean((gt_iou - pred_iou.squeeze()) ** 2)
        return iou_loss


class FocalDiceloss_IoULoss(nn.Module):
    def __init__(self, weight=20.0, iou_scale=1.0, ignore_index=255):
        super(FocalDiceloss_IoULoss, self).__init__()
        self.weight = weight
        self.iou_scale = iou_scale
        self.ignore_index = ignore_index
        
        self.focal_loss = FocalLoss(ignore_index=ignore_index)
        self.dice_loss = DiceLoss(ignore_index=ignore_index)
        self.maskiou_loss = MaskIoULoss(ignore_index=ignore_index)

    def forward(self, pred, mask, pred_iou):
        assert pred.shape == mask.shape, "pred and mask should have the same shape."

        focal_loss = self.focal_loss(pred, mask)
        dice_loss = self.dice_loss(pred, mask)
        
        loss1 = self.weight * focal_loss + dice_loss
        
        if pred_iou is not None:
            loss2 = self.maskiou_loss(pred, mask, pred_iou)
            loss = loss1 + loss2 * self.iou_scale
        else:
            loss = loss1
            
        return loss, {'focal': focal_loss.item(), 'dice': dice_loss.item()}

# ===  Point Guidance Loss ===
def point_guidance_loss(pred_heatmap, gt_nuclei):
    """
    è®¡ç®—çƒ­åŠ›å›¾ç”Ÿæˆçš„ MSE Loss (æ”¯æŒ 2é€šé“ è¾“å‡º)
    pred_heatmap: [B, 2, H, W] (Ch0: Foreground, Ch1: Background)
    gt_nuclei:    [B, 1, H, W] (0/1 Mask)
    """
    # 1. ç¡®ä¿ GT ç»´åº¦æ˜¯ [B, 1, H, W]
    if gt_nuclei.ndim == 3:
        gt_nuclei = gt_nuclei.unsqueeze(1)
        
    # 2. è·å–é¢„æµ‹çš„ sigmoid æ¦‚ç‡
    pred_prob = torch.sigmoid(pred_heatmap)

    # æƒ…å†µ A: æ¨¡å‹è¾“å‡º 2 ä¸ªé€šé“ (å‰æ™¯ + èƒŒæ™¯)
    if pred_heatmap.shape[1] == 2:
        # Channel 0 ç›‘ç£å‰æ™¯
        pred_fg = pred_prob[:, 0:1, :, :]
        loss_fg = F.mse_loss(pred_fg, gt_nuclei)
        
        # Channel 1 ç›‘ç£èƒŒæ™¯ (1 - GT)
        pred_bg = pred_prob[:, 1:2, :, :]
        gt_bg = 1.0 - gt_nuclei
        loss_bg = F.mse_loss(pred_bg, gt_bg)
        
        return loss_fg + loss_bg

    # æƒ…å†µ B: æ¨¡å‹åªè¾“å‡º 1 ä¸ªé€šé“
    else:
        return F.mse_loss(pred_prob, gt_nuclei)


# === ç‰©ç†-è¯­ä¹‰ä¸€è‡´æ€§ Loss ===
def physical_semantic_consistency_loss(
    peak_counts: torch.Tensor,
    density_logits: torch.Tensor,
    margin_low: float = 10.0,
    margin_high: float = 30.0,
    temperature: float = 1.0
):
    """
    ç‰©ç†-è¯­ä¹‰ä¸€è‡´æ€§ Loss ($L_{consistency}$)
    
    æ¯”è¾ƒçƒ­åŠ›å›¾è®¡æ•°ç­‰çº§å’Œåˆ†ç±»å¤´é¢„æµ‹ç­‰çº§ï¼Œä½¿ç”¨ Margin æœºåˆ¶å®ç°å®¹å·®è®¾è®¡ã€‚
    
    Args:
        peak_counts: [B] ä»çƒ­åŠ›å›¾ä¸­ç»Ÿè®¡çš„å³°å€¼æ•°é‡ $N_{pred}$
        density_logits: [B, 3] å¯†åº¦åˆ†ç±»å¤´çš„ logitsï¼ˆ3ç±»ï¼šä½ã€ä¸­ã€é«˜ï¼‰
        margin_low: float ä½å¯†åº¦é˜ˆå€¼ï¼ˆé»˜è®¤ 10ï¼‰
        margin_high: float é«˜å¯†åº¦é˜ˆå€¼ï¼ˆé»˜è®¤ 30ï¼‰
        temperature: float æ¸©åº¦å‚æ•°ï¼Œç”¨äºè½¯åŒ–é¢„æµ‹
    
    Returns:
        loss: scalar ä¸€è‡´æ€§æŸå¤±
    """
    device = peak_counts.device
    B = peak_counts.shape[0]
    
    # è·å–é¢„æµ‹çš„å¯†åº¦ç±»åˆ«ï¼ˆä½¿ç”¨ softmax è·å–æ¦‚ç‡åˆ†å¸ƒï¼‰
    density_probs = F.softmax(density_logits / temperature, dim=1)  # [B, 3]
    # 0: ä½å¯†åº¦, 1: ä¸­å¯†åº¦, 2: é«˜å¯†åº¦
    pred_class = torch.argmax(density_probs, dim=1)  # [B]
    
    # å®šä¹‰æ¯ä¸ªç±»åˆ«å¯¹åº”çš„è®¡æ•°èŒƒå›´
    # ä½å¯†åº¦: < margin_low (10)
    # ä¸­å¯†åº¦: margin_low ~ margin_high (10-30)
    # é«˜å¯†åº¦: > margin_high (30)
    
    # ä½¿ç”¨å‘é‡åŒ–æ“ä½œä¿æŒæ¢¯åº¦æµ
    # å°† peak_counts è½¬æ¢ä¸ºä¸ density_probs å…¼å®¹çš„å½¢çŠ¶
    n_pred = peak_counts.unsqueeze(1)  # [B, 1]
    
    # ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºæ©ç 
    is_low = (pred_class == 0).float().unsqueeze(1)  # [B, 1]
    is_mid = (pred_class == 1).float().unsqueeze(1)  # [B, 1]
    is_high = (pred_class == 2).float().unsqueeze(1)  # [B, 1]
    
    # è®¡ç®—æƒ©ç½šï¼ˆå‘é‡åŒ–ï¼‰
    # ä½å¯†åº¦ç±»åˆ«ï¼šå¦‚æœè®¡æ•° >= margin_lowï¼Œæƒ©ç½š
    penalty_low = torch.clamp((n_pred - margin_low) / margin_low, min=0.0) * is_low
    loss_low = (penalty_low * density_probs[:, 0:1]).sum()
    
    # ä¸­å¯†åº¦ç±»åˆ«ï¼šå¦‚æœè®¡æ•° < margin_low æˆ– > margin_highï¼Œæƒ©ç½š
    penalty_mid_low = torch.clamp((margin_low - n_pred) / margin_low, min=0.0) * is_mid
    penalty_mid_high = torch.clamp((n_pred - margin_high) / margin_high, min=0.0) * is_mid
    loss_mid = ((penalty_mid_low + penalty_mid_high) * density_probs[:, 1:2]).sum()
    
    # é«˜å¯†åº¦ç±»åˆ«ï¼šå¦‚æœè®¡æ•° < margin_highï¼Œæƒ©ç½š
    penalty_high = torch.clamp((margin_high - n_pred) / margin_high, min=0.0) * is_high
    loss_high = (penalty_high * density_probs[:, 2:3]).sum()
    
    # æ€»æŸå¤±
    loss = loss_low + loss_mid + loss_high
    
    # å¹³å‡åŒ–
    return loss / B if B > 0 else loss


def generate_density_map_from_mask(gt_mask: torch.Tensor, sigma: float = 2.0) -> torch.Tensor:
    """
    ä½¿ç”¨é«˜æ–¯å·ç§¯ç”Ÿæˆå¯†åº¦å›¾ (GPUåŠ é€Ÿç‰ˆï¼Œæ— å¾ªç¯)
    å‚è€ƒ DeNSe è®ºæ–‡ï¼šå°†æ¯ä¸ªç»†èƒæ ¸ä¸­å¿ƒç‚¹è½¬æ¢ä¸ºé«˜æ–¯åˆ†å¸ƒ
    ä½¿ç”¨å‘é‡åŒ–å·ç§¯æ“ä½œï¼Œæ¯”å¾ªç¯å¿« 1000+ å€
    
    Args:
        gt_mask: [H, W] æˆ– [1, H, W] æˆ– [B, 1, H, W] çš„ GT maskï¼ˆå€¼ä¸º 0 å’Œ 1ï¼Œæˆ– 0 å’Œ 255ï¼‰
        sigma: float é«˜æ–¯æ ¸çš„æ ‡å‡†å·®ï¼ˆæ§åˆ¶å¯†åº¦æ‰©æ•£èŒƒå›´ï¼‰
    
    Returns:
        density_map: [1, H, W] æˆ– [B, 1, H, W] çš„å¯†åº¦å›¾ï¼ˆå€¼åŸŸ [0, 1]ï¼‰
    """
    # 1. ç»´åº¦æ•´ç†
    if not isinstance(gt_mask, torch.Tensor):
        gt_mask = torch.tensor(gt_mask, dtype=torch.float32)
    
    original_shape = gt_mask.shape
    device = gt_mask.device
    
    # ç¡®ä¿æ˜¯ 4 ç»´å¼ é‡ [B, 1, H, W]
    if gt_mask.ndim == 2:
        gt_mask = gt_mask.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]
        batch_mode = False
    elif gt_mask.ndim == 3:
        gt_mask = gt_mask.unsqueeze(1)  # [B, 1, H, W] æˆ– [1, 1, H, W]
        batch_mode = (gt_mask.shape[0] > 1)
    else:
        batch_mode = (gt_mask.shape[0] > 1)
    
    # å°† mask å½’ä¸€åŒ–åˆ° [0, 1]
    if gt_mask.max() > 1:
        gt_mask = (gt_mask > 127).float()
    else:
        gt_mask = gt_mask.float()
    
    # 2. æå–ç»†èƒä¸­å¿ƒç‚¹ (åˆ©ç”¨ MaxPool æé€Ÿå®šä½)
    # ğŸ”¥ [æ ¸å¿ƒä¿®å¤]ï¼šä½¿ç”¨ padding=1ï¼Œç¡®ä¿è¾“å‡ºå°ºå¯¸ = è¾“å…¥å°ºå¯¸
    local_max = F.max_pool2d(gt_mask, kernel_size=3, stride=1, padding=1)
    # åªæœ‰å½“åƒç´ å€¼å¤§äº0.5ä¸”ç­‰äºå±€éƒ¨æœ€å¤§å€¼æ—¶ï¼Œæ‰è®¤ä¸ºæ˜¯ä¸­å¿ƒ
    centers = (gt_mask > 0.5) & (gt_mask == local_max)
    centers = centers.float()  # è½¬æ¢ä¸º 0.0 å’Œ 1.0 çš„æµ®ç‚¹æ•°å›¾ [B, 1, H, W]
    
    # 3. æ„å»ºé«˜æ–¯å·ç§¯æ ¸ (åªæ„å»ºä¸€æ¬¡ï¼Œå¯ç¼“å­˜)
    k_size = int(6 * sigma + 1)
    if k_size % 2 == 0: 
        k_size += 1  # ç¡®ä¿æ˜¯å¥‡æ•°
    
    # ç”Ÿæˆ 1D é«˜æ–¯å‘é‡
    x_coord = torch.arange(k_size, dtype=torch.float32, device=device) - k_size // 2
    gaussian_1d = torch.exp(-(x_coord ** 2) / (2 * sigma ** 2))
    
    # ç”Ÿæˆ 2D é«˜æ–¯æ ¸ [1, 1, K, K]
    gaussian_kernel = torch.outer(gaussian_1d, gaussian_1d)
    
    # ğŸ”¥ å½’ä¸€åŒ–ç­–ç•¥ï¼šä½¿ç”¨å³°å€¼å½’ä¸€åŒ–ï¼ˆå³°å€¼=1.0ï¼‰ï¼Œè€Œä¸æ˜¯æ€»å’Œå½’ä¸€åŒ–
    # åŸå› ï¼š1) ä¿æŒæ•°å€¼èŒƒå›´åˆç†ï¼Œé¿å…Lossè¿‡å° 2) æ›´ç¬¦åˆè§†è§‰çƒ­åŠ›å›¾çš„ç›´è§‚ç†è§£
    # å¦‚æœä½¿ç”¨æ€»å’Œå½’ä¸€åŒ–ï¼Œå³°å€¼ä¼šå¾ˆå°ï¼ˆå¦‚0.01ï¼‰ï¼Œå¯¼è‡´MSE Lossæå°
    # å³°å€¼å½’ä¸€åŒ–ï¼šæ¯ä¸ªç»†èƒçš„å³°å€¼æ˜¯1.0ï¼Œåˆ†æ•£åˆ°å‘¨å›´åæ•°å€¼èŒƒå›´åœ¨[0, 1]
    gaussian_kernel = gaussian_kernel / gaussian_kernel.max()  # å³°å€¼å½’ä¸€åŒ–
    gaussian_kernel = gaussian_kernel.view(1, 1, k_size, k_size)
    
    # 4. æ‰§è¡Œå·ç§¯ (ä¸€æ­¥åˆ°ä½ï¼Œä»£æ›¿æ‰€æœ‰å¾ªç¯) - GPUæœ€æ“…é•¿çš„æ“ä½œ
    # ğŸ”¥ [æ€§èƒ½ä¼˜åŒ–] ç›´æ¥å¯¹æ•´ä¸ªbatchè¿›è¡Œå·ç§¯ï¼Œæ— éœ€å¾ªç¯
    density_map = F.conv2d(centers, gaussian_kernel, padding=k_size//2)  # [B, 1, H, W]
    
    # 5. æœ€ç»ˆå½’ä¸€åŒ–ï¼ˆå¯é€‰ï¼‰
    # æ³¨æ„ï¼šä½¿ç”¨å³°å€¼å½’ä¸€åŒ–åï¼Œå¦‚æœå¤šä¸ªç»†èƒé‡å ï¼Œå€¼å¯èƒ½è¶…è¿‡1.0
    # è¿™æ˜¯åˆç†çš„ï¼ˆè¡¨ç¤ºè¯¥åŒºåŸŸæœ‰å¤šä¸ªç»†èƒï¼‰ï¼Œä½†ä¸ºäº†æ•°å€¼ç¨³å®šï¼Œæˆ‘ä»¬å¯ä»¥å½’ä¸€åŒ–åˆ°[0, 1]
    # æˆ–è€…ä¿æŒåŸæ ·ï¼Œè®©æ¨¡å‹å­¦ä¹ çœŸå®çš„å¯†åº¦å€¼
    # è¿™é‡Œæˆ‘ä»¬ä¿æŒåŸæ ·ï¼Œä¸è¿›è¡Œå…¨å±€å½’ä¸€åŒ–ï¼Œè®©æ¯ä¸ªç»†èƒçš„å³°å€¼ä¿æŒä¸º1.0
    
    # å¦‚æœåŸå§‹è¾“å…¥ä¸æ˜¯batchï¼Œè¿”å›å•æ ·æœ¬æ ¼å¼
    if not batch_mode and original_shape[0] != density_map.shape[0]:
        density_map = density_map[0]  # [1, H, W]
    
    return density_map


def density_map_loss(
    pred_density_map: torch.Tensor,
    gt_mask: torch.Tensor,
    pred_mask: torch.Tensor,
    mse_weight: float = 1.0,
    iou_weight: float = 0.5,
    enable_iou: bool = True
) -> torch.Tensor:
    """
    å¯†åº¦å›¾æŸå¤±å‡½æ•°ï¼ˆå‚è€ƒ DeNSe è®ºæ–‡ï¼Œæ”¯æŒä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼‰
    åŒ…å«ä¸¤éƒ¨åˆ†ï¼š
    1. MSE Loss: é¢„æµ‹å¯†åº¦å›¾ vs GT å¯†åº¦å›¾ï¼ˆå§‹ç»ˆå¯ç”¨ï¼‰
    2. IoU Loss: é¢„æµ‹ mask ä¸å¯†åº¦å›¾é«˜å“åº”åŒºåŸŸçš„é‡å ï¼ˆé¢„çƒ­æœŸå¯å…³é—­ï¼‰
    
    Args:
        pred_density_map: [B, 1, H, W] é¢„æµ‹çš„å¯†åº¦å›¾
        gt_mask: [B, 1, H, W] æˆ– [B, H, W] GT mask
        pred_mask: [B, 1, H, W] æˆ– [B, H, W] é¢„æµ‹çš„ maskï¼ˆlogitsï¼Œæœª sigmoidï¼‰
        mse_weight: float MSE æŸå¤±çš„æƒé‡
        iou_weight: float IoU æŸå¤±çš„æƒé‡
        enable_iou: bool æ˜¯å¦å¯ç”¨IoU Lossï¼ˆä¸¤é˜¶æ®µç­–ç•¥ï¼šé¢„çƒ­æœŸå…³é—­ï¼‰
    
    Returns:
        total_loss: scalar æ€»æŸå¤±
        mse_loss: scalar MSEæŸå¤±ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
        iou_loss: scalar IoUæŸå¤±ï¼ˆé¢„çƒ­æœŸä¸º0ï¼Œç”¨äºæ—¥å¿—è®°å½•ï¼‰
    """
    device = pred_density_map.device
    
    # ç¡®ä¿ç»´åº¦ä¸€è‡´
    if pred_density_map.dim() == 3:
        pred_density_map = pred_density_map.unsqueeze(1)
    if gt_mask.dim() == 3:
        gt_mask = gt_mask.unsqueeze(1)
    if pred_mask.dim() == 3:
        pred_mask = pred_mask.unsqueeze(1)
    
    B, _, H, W = pred_density_map.shape
    
    # è°ƒæ•´å¤§å°ä»¥åŒ¹é…
    if gt_mask.shape[-2:] != (H, W):
        gt_mask = F.interpolate(gt_mask.float(), size=(H, W), mode='nearest')
    if pred_mask.shape[-2:] != (H, W):
        pred_mask = F.interpolate(pred_mask.unsqueeze(0) if pred_mask.dim() == 2 else pred_mask, 
                                  size=(H, W), mode='bilinear', align_corners=False)
    
    # ğŸ”¥ [æ€§èƒ½ä¼˜åŒ–] æ‰¹é‡ç”Ÿæˆ GT å¯†åº¦å›¾ï¼ˆé¿å…å¾ªç¯ï¼‰
    # ç›´æ¥ä¼ å…¥æ•´ä¸ªbatch [B, 1, H, W]ï¼Œå‡½æ•°å†…éƒ¨ä¼šé«˜æ•ˆå¤„ç†
    gt_density_map = generate_density_map_from_mask(gt_mask, sigma=2.0)  # [B, 1, H, W]
    # ç¡®ä¿ç»´åº¦æ­£ç¡®
    if gt_density_map.dim() == 3:
        gt_density_map = gt_density_map.unsqueeze(1)  # [B, 1, H, W]
    
    # 1. MSE Loss: é¢„æµ‹å¯†åº¦å›¾ vs GT å¯†åº¦å›¾ï¼ˆå§‹ç»ˆå¯ç”¨ï¼‰
    mse_loss = F.mse_loss(pred_density_map, gt_density_map)
    
    # 2. IoU Loss: é¢„æµ‹ mask ä¸å¯†åº¦å›¾é«˜å“åº”åŒºåŸŸçš„é‡å ï¼ˆä¸¤é˜¶æ®µç­–ç•¥ï¼šé¢„çƒ­æœŸå…³é—­ï¼‰
    # ğŸ”¥ [ä¸¤é˜¶æ®µç­–ç•¥] å‰20ä¸ªepochåªè®¡ç®—MSEï¼Œè®©PNuRLå…ˆå­¦ä¼š"çœ‹å›¾"
    # 20ä¸ªepochåå¼€å¯IoUï¼Œåˆ©ç”¨å·²ç»å‡†äº†çš„å¯†åº¦å›¾å»ä¿®å‰ªSAMçš„Mask
    iou_loss = torch.tensor(0.0, device=mse_loss.device)
    if enable_iou:
        # å°†é¢„æµ‹ mask è½¬æ¢ä¸ºäºŒå€¼åŒ–
        pred_mask_binary = torch.sigmoid(pred_mask) > 0.5  # [B, 1, H, W]
        
        # å¯†åº¦å›¾çš„é«˜å“åº”åŒºåŸŸï¼ˆé˜ˆå€¼å¯è°ƒï¼‰
        density_threshold = 0.3
        density_high_response = (pred_density_map > density_threshold).float()  # [B, 1, H, W]
        
        # è®¡ç®— IoU
        intersection = (pred_mask_binary.float() * density_high_response).sum(dim=[2, 3])  # [B, 1]
        union = (pred_mask_binary.float() + density_high_response - 
                 pred_mask_binary.float() * density_high_response).sum(dim=[2, 3])  # [B, 1]
        
        iou = (intersection + 1e-6) / (union + 1e-6)  # [B, 1]
        iou_loss = 1.0 - iou.mean()  # è½¬æ¢ä¸ºæŸå¤±ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        
        # æ€»æŸå¤±ï¼šMSE + IoU
        total_loss = mse_weight * mse_loss + iou_weight * iou_loss
    else:
        # é¢„çƒ­æœŸï¼šåªè®¡ç®—MSEï¼Œè®©PNuRLå…ˆå­¦ä¼šç”Ÿæˆå¯†åº¦å›¾
        total_loss = mse_weight * mse_loss
    
    # è¿”å›æ€»æŸå¤±å’Œç»„ä»¶ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
    return total_loss, mse_loss, iou_loss