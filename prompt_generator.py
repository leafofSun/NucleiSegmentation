import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from scipy.spatial import KDTree

class TextGuidedPointGenerator(nn.Module):
    def __init__(self, embed_dim=256, text_dim=512):
        super().__init__()
        # 1. æ–‡æœ¬æŠ•å½±å±‚
        self.text_proj = nn.Linear(text_dim, embed_dim)
        
        # 2. å›¾åƒå·ç§¯å±‚ (æå–å±€éƒ¨ç‰¹å¾)
        self.img_conv = nn.Sequential(
            nn.Conv2d(embed_dim, embed_dim, kernel_size=3, padding=1),
            nn.BatchNorm2d(embed_dim),
            nn.ReLU(inplace=True)
        )
        
        # 3. Logit Scale
        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))

    def forward(self, image_embeddings, text_embeddings):
        B, C, H, W = image_embeddings.shape
        _, N_Classes, _ = text_embeddings.shape 
        
        img_feat = self.img_conv(image_embeddings) 
        txt_feat = self.text_proj(text_embeddings)
        
        img_feat = F.normalize(img_feat, dim=1)      
        txt_feat = F.normalize(txt_feat, dim=-1)     

        img_flat = img_feat.view(B, C, -1)           
        match_score = torch.bmm(txt_feat, img_flat)  
        
        logit_scale = self.logit_scale.exp().clamp(max=100)
        match_score = match_score * logit_scale
        
        heatmap_logits = match_score.view(B, N_Classes, H, W)
        return heatmap_logits

    @torch.no_grad()
    def generate_adaptive_prompts(self, heatmap_logits, threshold=0.3, k_neighbors=3, dense_dist_thresh=15.0, max_points=None):
        """
        ğŸ”¥ [æ ¸å¿ƒä¿®æ­£] å…¨å±€é‚»åŸŸæ„å»º + éšæœºé‡‡æ ·è®­ç»ƒ (Global Neighborhood + Random Sampling)
        
        é€»è¾‘æµï¼š
        1. æå–å…¨å›¾æ‰€æœ‰æ½œåœ¨ç»†èƒç‚¹ (All Points)ã€‚
        2. åŸºäº All Points æ„å»º KDTreeï¼Œç¡®ä¿é‚»å±…å…³ç³»çš„ç‰©ç†çœŸå®æ€§ (Neighbor Integrity)ã€‚
        3. å¦‚æœè®­ç»ƒéœ€è¦é™åˆ¶æ•°é‡ (max_points)ï¼Œåˆ™ä» All Points ä¸­ã€éšæœºé‡‡æ ·ã€‘N ä¸ªä½œä¸ºç›®æ ‡ã€‚
           æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ Random è€Œä¸æ˜¯ Top-Kï¼Œä»¥ä¿è¯æ¨¡å‹è§è¿‡"å·®ç”Ÿ"(ä½ç½®ä¿¡åº¦æ ·æœ¬)ã€‚
        4. ä¸ºè¿™ N ä¸ªç›®æ ‡æ„å»º Promptï¼Œå…¶è´Ÿæç¤ºæ¥æºäº KDTree (å³æ¥æºäºå…¨é›†)ã€‚
        """
        B, C, H, W = heatmap_logits.shape
        device = heatmap_logits.device
        
        # 1. NMS æå–æ‰€æœ‰ç‚¹
        scores = torch.sigmoid(heatmap_logits)
        local_max = F.max_pool2d(scores, kernel_size=5, stride=1, padding=2)
        is_local_max = (scores == local_max) & (scores > threshold)
        
        batch_prompts = []

        for b in range(B):
            fg_map = is_local_max[b, 0] 
            y_inds, x_inds = torch.where(fg_map)
            
            # === æƒ…å†µ A: å›¾ä¸­æ— ç»†èƒ ===
            if len(y_inds) == 0:
                batch_prompts.append({
                    "point_coords": torch.empty((0, k_neighbors + 1, 2), device=device),
                    "point_labels": torch.empty((0, k_neighbors + 1), device=device),
                    "has_points": False
                })
                continue
                
            # === å…³é”®æ­¥éª¤ 1: è·å–å…¨é‡ç‚¹é›† (Global Set) ===
            # è¿™äº›ç‚¹æ—¢æ˜¯æ½œåœ¨çš„ Targetï¼Œä¹Ÿæ˜¯æ½œåœ¨çš„ Negative Neighbor
            all_points_np = torch.stack([x_inds.float(), y_inds.float()], dim=1).cpu().numpy()
            total_num_points = len(all_points_np)
            
            # === å…³é”®æ­¥éª¤ 2: åŸºäºå…¨é‡ç‚¹é›†æ„å»º KDTree (ä¿è¯é‚»å±…å®Œæ•´æ€§) ===
            # æ— è®ºæˆ‘ä»¬åé¢é‡‡æ ·å“ª 50 ä¸ªè®­ç»ƒï¼Œæ‰¾é‚»å±…å¿…é¡»åœ¨å…¨é›†é‡Œæ‰¾ï¼
            tree = None
            dists_all, indices_all = None, None
            
            if total_num_points > 1:
                tree = KDTree(all_points_np)
                # é¢„å…ˆè®¡ç®—æ‰€æœ‰ç‚¹çš„é‚»å±…ä¿¡æ¯ (æŸ¥è¯¢ k+1 ä¸ªï¼ŒåŒ…å«è‡ªå·±)
                k_query = min(total_num_points, k_neighbors + 1)
                dists_all, indices_all = tree.query(all_points_np, k=k_query)

            # === å…³é”®æ­¥éª¤ 3: ç¡®å®šè®­ç»ƒç›®æ ‡ (Target Selection) ===
            # é»˜è®¤ä½¿ç”¨æ‰€æœ‰ç‚¹
            target_indices = np.arange(total_num_points)
            
            # å¦‚æœç‚¹æ•°è¶…è¿‡é™åˆ¶ï¼Œè¿›è¡Œã€éšæœºé‡‡æ ·ã€‘ï¼Œè€Œä¸æ˜¯ Top-K
            # max_points é€šå¸¸åœ¨è®­ç»ƒæ—¶è®¾ä¸º 50ï¼ŒéªŒè¯æ—¶è®¾ä¸º None
            if max_points is not None and total_num_points > max_points:
                # ğŸ”¥ [ç­–ç•¥ä¿®æ­£] ä½¿ç”¨éšæœºé‡‡æ ·ï¼Œä¿è¯æ³›åŒ–æ€§
                # replace=False è¡¨ç¤ºä¸é‡å¤é‡‡æ ·
                target_indices = np.random.choice(total_num_points, max_points, replace=False)
                
            # === å…³é”®æ­¥éª¤ 4: æ„å»º Prompt (åªé’ˆå¯¹é€‰ä¸­çš„ Target) ===
            image_point_coords = []
            image_point_labels = []

            for i in target_indices:
                # 1. æ­£æç¤º (Self) - æ¥æºäºå…¨é›†
                current_pt = all_points_np[i]
                pts = [current_pt]
                lbls = [1] # 1 = Positive
                
                # 2. å¯†åº¦åˆ¤æ–­ & è´Ÿæç¤ºæ³¨å…¥ (ä½¿ç”¨å…¨é›†çš„ KDTree ç»“æœ)
                is_crowded = False
                if dists_all is not None:
                    # è·å–ç¬¬ i ä¸ªç‚¹çš„é‚»å±…è·ç¦»ä¿¡æ¯
                    d_i = dists_all[i] # è·ç¦»æ•°ç»„
                    idx_i = indices_all[i] # é‚»å±…ç´¢å¼•æ•°ç»„
                    
                    if np.size(d_i) > 1:
                        # å…¼å®¹ shape
                        if d_i.ndim == 0: d_i = [d_i] 
                        
                        # dists_all[i][1] æ˜¯æœ€è¿‘é‚»å±…çš„è·ç¦» (index 0 æ˜¯è‡ªå·±)
                        if len(d_i) > 1:
                            nearest_dist = d_i[1]
                            if nearest_dist < dense_dist_thresh:
                                is_crowded = True
                
                # 3. è´Ÿæç¤ºæ³¨å…¥ (Neighboring Negatives)
                if is_crowded:
                    # éå†é‚»å±… (è·³è¿‡ä¸‹æ ‡0ï¼Œå› ä¸ºæ˜¯è‡ªå·±)
                    # æ³¨æ„ï¼šidx_i é‡Œé¢å­˜çš„æ˜¯åœ¨ all_points_np ä¸­çš„ä¸‹æ ‡
                    # å³ä½¿æŸä¸ªé‚»å±…æ²¡æœ‰è¢«é€‰è¿› target_indicesï¼Œå®ƒä¾ç„¶ä¼šè¢«åŠ è¿›æ¥åšè´Ÿæç¤ºï¼âœ…
                    current_neighbors = idx_i if np.ndim(idx_i) > 0 else [idx_i]
                    
                    for j in range(1, len(current_neighbors)):
                        neighbor_idx = current_neighbors[j]
                        # åªæœ‰å½“ neighbor_idx æœ‰æ•ˆæ—¶
                        if neighbor_idx < total_num_points:
                            neighbor_pt = all_points_np[neighbor_idx]
                            pts.append(neighbor_pt)
                            lbls.append(0) # 0 = Negative
                
                # 4. Padding
                while len(pts) < k_neighbors + 1:
                    pts.append([0.0, 0.0]) 
                    lbls.append(-1)
                
                image_point_coords.append(pts)
                image_point_labels.append(lbls)

            # è½¬ä¸º Tensor
            batch_prompts.append({
                "point_coords": torch.tensor(np.array(image_point_coords), device=device).float(),
                "point_labels": torch.tensor(np.array(image_point_labels), device=device).long(),
                "has_points": True
            })
            
        return batch_prompts

# === Loss å‡½æ•° ===
def point_guidance_loss(pred_heatmap_logits, target_heatmap):
    """
    pred_heatmap_logits: [B, C, H, W] (æœªè¿‡ sigmoid)
    target_heatmap:      [B, C, H, W] (DataLoaderç”Ÿæˆçš„æ¤­åœ†çƒ­åŠ›å›¾)
    """
    pred_prob = torch.sigmoid(pred_heatmap_logits)
    return focal_loss(pred_prob, target_heatmap)

def focal_loss(pred, target, alpha=2, beta=4):
    """
    CenterNet é£æ ¼ Focal Loss
    """
    pos_inds = target.eq(1).float()
    neg_inds = target.lt(1).float()
    neg_weights = torch.pow(1 - target, beta)
    
    loss = 0
    pred = torch.clamp(pred, 1e-6, 1 - 1e-6)
    
    pos_loss = torch.log(pred) * torch.pow(1 - pred, alpha) * pos_inds
    neg_loss = torch.log(1 - pred) * torch.pow(pred, alpha) * neg_weights * neg_inds
    
    num_pos = pos_inds.float().sum()
    pos_loss = pos_loss.sum()
    neg_loss = neg_loss.sum()
    
    if num_pos == 0:
        loss = -neg_loss
    else:
        loss = -(pos_loss + neg_loss) / num_pos
    return loss