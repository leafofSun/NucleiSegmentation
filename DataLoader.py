import os
import cv2
import json
import torch
import numpy as np
import random
import glob
from torch.utils import data
import albumentations as A
from albumentations.pytorch import ToTensorV2

# å°è¯•å¯¼å…¥ COCO å·¥å…·
try:
    from pycocotools import mask as coco_mask
except ImportError:
    print("âš ï¸ [DataLoader] pycocotools not installed. SA-1B RLE decoding might fail.")

# === ğŸ”¥ æ ¸å¿ƒç»„ä»¶ 1: åŒ»å­¦å›°éš¾è´Ÿæ ·æœ¬æ±  (Hard Negatives) ===
# è¿™äº›è¯ä¼šè®©æ¨¡å‹å­¦ä¼šåŒºåˆ†â€œç»†èƒæ ¸â€å’Œâ€œé•¿å¾—åƒç»†èƒæ ¸çš„ä¸œè¥¿â€
NEGATIVE_PROMPTS = [
    # Level 1: æœ€éš¾çš„å¹²æ‰° (ç”Ÿç‰©å­¦ç›¸ä¼¼)
    "Red blood cells", "Eosinophilic cytoplasm", "Stromal tissue", 
    "Extracellular matrix", "Collagen fibers", "Adipose tissue cells",
    "Blood vessel lumen",
    # Level 2: ä¼ªå½±ä¸èƒŒæ™¯
    "Tissue folds", "Air bubbles", "Glass slide background", "Blurred regions",
    # Level 3: è¯­ä¹‰é™·é˜± & é€šç”¨ç‰©ä½“
    "Mitochondria", "Golgi apparatus", "A photo of a cat", "A car"
]

def stack_dict_batched(batch):
    """è‡ªå®šä¹‰ collate_fn"""
    tensor_dict = {}
    for key, value in batch[0].items():
        if key == 'text_prompt' or key == 'name':
            tensor_dict[key] = [sample[key] for sample in batch]
        elif isinstance(value, torch.Tensor):
            tensor_dict[key] = torch.stack([sample[key] for sample in batch])
        else:
            tensor_dict[key] = [sample[key] for sample in batch]
    return tensor_dict

class TrainingDataset(data.Dataset):
    def __init__(self, data_dir, image_size=1024, crop_size=256, mode='train', 
                 mask_num=1, requires_name=True, 
                 # ğŸ”¥ æ³¨æ„ï¼šè¿™é‡Œæ”¹æˆåŠ è½½æ–°çš„åŠ¨æ€å±æ€§åº“
                 dynamic_attr_path="data/MoNuSeg_SA1B/dynamic_instance_attributes.json"):
        
        self.data_dir = data_dir
        self.image_size = image_size
        self.crop_size = crop_size
        self.mode = mode
        
        # === 1. åŠ è½½åŠ¨æ€å±æ€§æ•°æ®åº“ ===
        self.dynamic_attrs = {}
        if os.path.exists(dynamic_attr_path):
            print(f"ğŸ“– [DataLoader] Loading Dynamic Attributes from {dynamic_attr_path}...")
            with open(dynamic_attr_path, 'r') as f:
                content = json.load(f)
                self.dynamic_attrs = content.get("images", {})
        else:
            if mode == 'train':
                print(f"âš ï¸ [DataLoader] CRITICAL WARNING: {dynamic_attr_path} not found!")
                print("   Model will NOT learn controllable segmentation without this file.")

        # === 2. æ‰«ææ–‡ä»¶ ===
        self.image_paths = []
        extensions = ['*.tif', '*.png', '*.jpg', '*.jpeg']
        for ext in extensions:
            self.image_paths.extend(glob.glob(os.path.join(data_dir, "**", ext), recursive=True))
        
        self.image_paths = [p for p in self.image_paths if "mask" not in p.lower()]
        
        # åªä¿ç•™æœ‰å¯¹åº” JSON çš„å›¾ç‰‡
        valid_paths = []
        for p in self.image_paths:
            base, _ = os.path.splitext(p)
            if os.path.exists(base + ".json"):
                valid_paths.append(p)
        
        if len(valid_paths) > 0:
            self.image_paths = valid_paths
            print(f"âœ… [DataLoader] Found {len(self.image_paths)} valid image-json pairs.")
        else:
            print(f"âš ï¸ [DataLoader] No valid pairs found! Dynamic GT requires JSONs.")

        # === 3. å¢å¼ºç­–ç•¥ (è®­ç»ƒæ—¶å¿…é¡»å¼ºåŠ›å¢å¼º) ===
        if mode == 'train':
            self.transform = A.Compose([
                A.RandomCrop(width=crop_size, height=crop_size, p=1.0),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),
                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),
                A.Resize(height=image_size, width=image_size, interpolation=cv2.INTER_LINEAR),
                ToTensorV2(),
            ])
        else:
            self.transform = A.Compose([
                A.CenterCrop(width=crop_size, height=crop_size, p=1.0),
                A.Resize(height=image_size, width=image_size, interpolation=cv2.INTER_LINEAR),
                ToTensorV2(),
            ])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, index):
        img_path = self.image_paths[index]
        filename = os.path.basename(img_path)
        base_name = os.path.splitext(img_path)[0]
        json_path = base_name + ".json"
        
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        h, w = image.shape[:2]
        
        # === ğŸ”¥ æ ¸å¿ƒé€»è¾‘ 2: é‡‡æ ·ç­–ç•¥é€‰æ‹© ===
        # é»˜è®¤å€¼
        prompt_mode = "Generic" 
        target_tag = None
        text_prompt = "Cell nuclei"
        
        if self.mode == 'train':
            rand = random.random()
            
            # ğŸŒ‘ ç­–ç•¥ A (20%): è´Ÿæ ·æœ¬ (Negative) -> è®­ç»ƒæ‹’ç»èƒ½åŠ›
            if rand < 0.2:
                prompt_mode = "Negative"
                text_prompt = random.choice(NEGATIVE_PROMPTS)
                
            # ğŸ¯ ç­–ç•¥ B (40%): å±æ€§ç‰¹å®š (Attribute) -> è®­ç»ƒç­›é€‰èƒ½åŠ›
            elif rand < 0.6 and filename in self.dynamic_attrs:
                instances = self.dynamic_attrs[filename]
                all_tags = []
                for inst in instances:
                    all_tags.extend(inst.get('tags', []))
                
                if len(all_tags) > 0:
                    prompt_mode = "Attribute"
                    # éšæœºé€‰ä¸€ä¸ªæ ‡ç­¾ï¼Œä¾‹å¦‚ "Small", "Round"
                    target_tag = random.choice(list(set(all_tags))) 
                    text_prompt = f"{target_tag} cell nuclei"
                else:
                    prompt_mode = "Generic"
            
            # ğŸŒ• ç­–ç•¥ C (40%): é€šç”¨ (Generic) -> ä¿æŒåŸºç¡€èƒ½åŠ›
            else:
                prompt_mode = "Generic"
                text_prompt = "Cell nuclei"

        # === ğŸ”¥ æ ¸å¿ƒé€»è¾‘ 3: åŠ¨æ€ Mask æ„å»º (Dynamic Mask Construction) ===
        # 0: èƒŒæ™¯, 1: ç›®æ ‡, 255: å¿½ç•¥ (å†²çªåŒºåŸŸ)
        IGNORE_INDEX = 255 
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # è´Ÿæ ·æœ¬æ¨¡å¼ï¼šMask å…¨é»‘ï¼Œæ— éœ€è¯»å– JSON
        if prompt_mode == "Negative":
            pass 
            
        elif os.path.exists(json_path):
            try:
                with open(json_path, 'r') as f:
                    data = json.load(f)
                anns = data.get('annotations', [])
                if not anns and isinstance(data, list): anns = data
                
                # ç¡®å®šå“ªäº› ID æ˜¯æ­£æ ·æœ¬ï¼Œå“ªäº›æ˜¯å¿½ç•¥æ ·æœ¬
                target_ids = set()
                ignore_ids = set()
                
                if prompt_mode == "Attribute" and filename in self.dynamic_attrs:
                    instances_info = self.dynamic_attrs[filename]
                    for inst in instances_info:
                        tags = inst.get('tags', [])
                        if target_tag in tags:
                            target_ids.add(inst['id'])
                        else:
                            # è¿™æ˜¯ä¸€ä¸ªç»†èƒï¼Œä½†ä¸æ˜¯æˆ‘ä»¬è¦æ‰¾çš„ -> è®¾ä¸ºå¿½ç•¥
                            ignore_ids.add(inst['id'])
                            
                elif prompt_mode == "Generic":
                    # é€šç”¨æ¨¡å¼ä¸‹ï¼Œæ‰€æœ‰ç»†èƒéƒ½æ˜¯ç›®æ ‡
                    target_ids = set(range(len(anns)))

                # ç»˜åˆ¶ Mask
                for idx, ann in enumerate(anns):
                    is_target = idx in target_ids
                    is_ignore = idx in ignore_ids
                    
                    if not (is_target or is_ignore): continue
                    
                    if 'segmentation' in ann:
                        seg = ann['segmentation']
                        # RLE decoding
                        if isinstance(seg, dict) and 'counts' in seg:
                            m = coco_mask.decode(seg)
                        # Polygon decoding
                        elif isinstance(seg, list):
                            m = np.zeros((h, w), dtype=np.uint8)
                            for poly in seg:
                                pts = np.array(poly, dtype=np.int32).reshape((-1, 2))
                                cv2.fillPoly(m, [pts], 1)
                        else:
                            continue
                            
                        # èµ‹å€¼
                        if is_target:
                            mask[m > 0] = 1
                        elif is_ignore:
                            # æ³¨æ„ï¼šä¸è¦è¦†ç›–å·²ç»æ˜¯ 1 çš„åŒºåŸŸ (é˜²æ­¢é‡å æ—¶è¦†ç›–)
                            mask[(m > 0) & (mask == 0)] = IGNORE_INDEX
                                
            except Exception as e:
                print(f"Error loading JSON {json_path}: {e}")

        # === 4. å¢å¼º ===
        # æ³¨æ„ï¼šæ’å€¼å¿…é¡»ç”¨ nearestï¼Œå¦åˆ™ 255 ä¼šå˜æˆ 254, 253...
        # albumentations å¯¹ mask é»˜è®¤å°±æ˜¯ nearestï¼Œä½†ä¸ºäº†ä¿é™©èµ·è§ï¼Œæˆ‘ä»¬åœ¨å¤–éƒ¨ä¸æ‰‹åŠ¨æ”¹
        augmented = self.transform(image=image, mask=mask)
        
        image_tensor = augmented['image'].float()
        
        # Mask éœ€è¦ä¿æŒ long ç±»å‹ä»¥ä¾¿ CrossEntropy ä½¿ç”¨ï¼Œæˆ–è€… float ç»™ Dice
        # è¿™é‡Œçš„ mask åŒ…å« 0, 1, 255
        mask_tensor = augmented['mask'].long().unsqueeze(0) 
        
        sample = {
            'image': image_tensor,
            'label': mask_tensor,
            'original_size': (self.image_size, self.image_size),
            'name': filename,
            'text_prompt': text_prompt
        }
        
        return sample