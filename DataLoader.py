import os
import cv2
import json
import torch
import numpy as np
from torch.utils import data
import glob
import albumentations as A
from albumentations.pytorch import ToTensorV2

# è§£æ SA-1B æ ¼å¼å¿…é¡»ç”¨ pycocotools
try:
    from pycocotools import mask as coco_mask
except ImportError:
    print("âš ï¸ [DataLoader] pycocotools not installed. SA-1B RLE decoding might fail.")

def stack_dict_batched(batch):
    """
    è‡ªå®šä¹‰ collate_fnï¼Œç”¨äºå¤„ç†å­—å…¸åˆ—è¡¨
    """
    tensor_dict = {}
    for key, value in batch[0].items():
        if key == 'text_prompt' or key == 'name':
            tensor_dict[key] = [sample[key] for sample in batch]
        elif isinstance(value, torch.Tensor):
            tensor_dict[key] = torch.stack([sample[key] for sample in batch])
        elif isinstance(value, np.ndarray):
            tensor_dict[key] = torch.stack([torch.from_numpy(sample[key]) for sample in batch])
        else:
            tensor_dict[key] = [sample[key] for sample in batch]
    return tensor_dict

class TrainingDataset(data.Dataset):
    def __init__(self, data_dir, image_size=1024, crop_size=256, mode='train', point_num=1, mask_num=5, requires_name=True, prompt_path="data/prompt_info.json"):
        """
        Args:
            data_dir: æ•°æ®è·¯å¾„
            image_size: æ¨¡å‹è¾“å…¥å°ºå¯¸ (å»ºè®® 1024, é€‚é… SAM ViT)
            crop_size: ä»åŸå›¾è£å‰ªçš„ Patch å¤§å° (å»ºè®® 256, æ¨¡æ‹Ÿæ»‘åŠ¨çª—å£)
            mode: 'train' å¼€å¯å¢å¼º, 'test' ä»…ä¸­å¿ƒè£å‰ª
        """
        self.data_dir = data_dir
        self.image_size = image_size
        self.crop_size = crop_size
        self.mode = mode
        self.point_num = point_num
        self.mask_num = mask_num
        self.requires_name = requires_name
        
        # === 1. åŠ è½½ Prompt JSON ===
        self.prompt_dict = {}
        if os.path.exists(prompt_path):
            print(f"ğŸ“– [DataLoader] Loading Prompts from {prompt_path}...")
            with open(prompt_path, 'r') as f:
                self.prompt_dict = json.load(f)
        else:
            # è®­ç»ƒæ—¶å¿…é¡»è¦æœ‰ Promptï¼Œå¦åˆ™æ‰“å°è­¦å‘Š
            if mode == 'train':
                print(f"âš ï¸ [DataLoader] Warning: {prompt_path} not found! Will use default prompts.")

        # === 2. æ‰«ææ–‡ä»¶ ===
        self.image_paths = []
        extensions = ['*.tif', '*.png', '*.jpg', '*.jpeg']
        for ext in extensions:
            self.image_paths.extend(glob.glob(os.path.join(data_dir, "**", ext), recursive=True))
            
        # è¿‡æ»¤æ‰ mask å›¾ç‰‡
        self.image_paths = [p for p in self.image_paths if "mask" not in p.lower()]
        
        # ç­›é€‰æœ‰å¯¹åº” JSON çš„å›¾ç‰‡
        valid_paths = []
        for p in self.image_paths:
            base, _ = os.path.splitext(p)
            if os.path.exists(base + ".json"):
                valid_paths.append(p)
        
        if len(valid_paths) > 0:
            self.image_paths = valid_paths
            print(f"âœ… [DataLoader] Found {len(self.image_paths)} images with matching SA-1B JSONs.")
        else:
            print(f"âš ï¸ [DataLoader] No JSONs found! Found {len(self.image_paths)} images (assuming masks implied).")

        # === 3. å®šä¹‰å¢å¼ºç­–ç•¥ (Albumentations) ===
        # æ³¨æ„ï¼šè¿™é‡Œä¸ä½¿ç”¨ A.Normalizeï¼Œå› ä¸º SAM æ¨¡å‹å†…éƒ¨æœ‰è‡ªå·±çš„ preprocess
        # æˆ‘ä»¬åªè´Ÿè´£å‡ ä½•å˜æ¢å’Œ resizeï¼Œè¾“å‡º 0-255 çš„ tensor
        
        if mode == 'train':
            self.transform = A.Compose([
                # ç©ºé—´å¢å¼ºï¼šæ¨¡æ‹Ÿæ»‘åŠ¨çª—å£ï¼Œä¿è¯å¤šæ ·æ€§
                A.RandomCrop(width=crop_size, height=crop_size, p=1.0),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                # å¼¹æ€§å½¢å˜ï¼šéå¸¸é€‚åˆç»†èƒæ ¸è¿™ç§è½¯ç»„ç»‡
                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),
                
                # é¢œè‰²å¢å¼ºï¼šç—…ç†å›¾åƒçš„æ ¸å¿ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆç‰¹å®šæŸ“è‰²é£æ ¼
                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),
                # A.GaussNoise(var_limit=(10.0, 50.0), p=0.2), # å¯é€‰
                
                # æ ¸å¿ƒæ­¥éª¤ï¼šæ”¾å¤§åˆ° 1024ï¼Œæ¿€æ´» ViT çš„ç»†èŠ‚æ„ŸçŸ¥èƒ½åŠ›
                A.Resize(height=image_size, width=image_size, interpolation=cv2.INTER_LINEAR),
                
                # è½¬ Tensor (C, H, W)
                ToTensorV2(),
            ])
        else:
            # éªŒè¯/æµ‹è¯•ï¼šä¿æŒä¸€è‡´çš„é¢„å¤„ç†ï¼Œä½†ä¸åšéšæœºå¢å¼º
            # ä½¿ç”¨ CenterCrop å–ä¸­é—´ä¸€å—ä»£è¡¨æ€§åŒºåŸŸè¿›è¡ŒéªŒè¯
            self.transform = A.Compose([
                A.CenterCrop(width=crop_size, height=crop_size, p=1.0),
                A.Resize(height=image_size, width=image_size, interpolation=cv2.INTER_LINEAR),
                ToTensorV2(),
            ])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, index):
        img_path = self.image_paths[index]
        filename = os.path.basename(img_path)
        
        # 1. è¯»å–å›¾åƒ
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        h, w = image.shape[:2]
        
        # 2. è¯»å– Label (SA-1B JSON)
        base_name, _ = os.path.splitext(img_path)
        json_path = base_name + ".json"
        
        mask = np.zeros((h, w), dtype=np.uint8)
        
        if os.path.exists(json_path):
            try:
                with open(json_path, 'r') as f:
                    data = json.load(f)
                
                anns = data.get('annotations', [])
                if not anns and isinstance(data, list): anns = data
                
                for ann in anns:
                    if 'segmentation' in ann:
                        seg = ann['segmentation']
                        # RLE
                        if isinstance(seg, dict) and 'counts' in seg:
                            rle_mask = coco_mask.decode(seg)
                            mask[rle_mask > 0] = 1
                        # Polygon
                        elif isinstance(seg, list):
                            for poly in seg:
                                pts = np.array(poly, dtype=np.int32).reshape((-1, 2))
                                cv2.fillPoly(mask, [pts], 1)
            except Exception as e:
                print(f"Error loading JSON {json_path}: {e}")
        else:
            # å›é€€ç­–ç•¥
            mask_path = img_path.replace(".tif", ".png").replace(".jpg", ".png").replace("Images", "Labels")
            if os.path.exists(mask_path):
                 m_temp = cv2.imread(mask_path, 0)
                 if m_temp is not None: mask = (m_temp > 0).astype(np.uint8)

        # 3. åº”ç”¨å¢å¼º (Augmentation & Resize)
        # albumentations ä¼šè‡ªåŠ¨åŒæ—¶å¤„ç† image å’Œ mask
        augmented = self.transform(image=image, mask=mask)
        
        image_tensor = augmented['image'].float() # [3, 1024, 1024], 0-255
        mask_tensor = augmented['mask'].float().unsqueeze(0) # [1, 1024, 1024], 0/1
        
        # 4. è·å– Prompt
        text_prompt = "Cell nuclei"
        if filename in self.prompt_dict:
            info = self.prompt_dict[filename]
            # ä¼˜å…ˆä½¿ç”¨ rich_text
            text_prompt = info.get("rich_text", info.get("target_text", "Cell nuclei"))

        # 5. æ„é€ è¿”å›æ ·æœ¬
        sample = {
            'image': image_tensor,
            'label': mask_tensor,
            # è¿™é‡Œçš„ original_size å‘Šè¯‰ SAM åå¤„ç†å±‚ï¼šç°åœ¨çš„ç‰¹å¾å›¾å¯¹åº”çš„æ˜¯å¤šå¤§çš„å›¾
            # å› ä¸ºæˆ‘ä»¬ Resize åˆ°äº† 1024ï¼Œæ‰€ä»¥è¿™é‡Œåº”è¯¥æ˜¯ (1024, 1024)
            # è¿™æ · SAM ç”Ÿæˆçš„ mask å°±ä¼šå’Œæˆ‘ä»¬çš„ label å¯¹é½
            'original_size': (self.image_size, self.image_size), 
            'name': filename,
            'text_prompt': text_prompt
        }
        
        return sample