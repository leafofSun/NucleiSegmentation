import os
import cv2
import json
import torch
import numpy as np
import random
import glob
from torch.utils import data
import albumentations as A
from albumentations.pytorch import ToTensorV2

# å°è¯•å¯¼å…¥ COCO å·¥å…·
try:
    from pycocotools import mask as coco_mask
except ImportError:
    print("âš ï¸ [DataLoader] pycocotools not installed. SA-1B RLE decoding might fail.")

# === ğŸ”¥ æ ¸å¿ƒç»„ä»¶ 1: åŒ»å­¦å›°éš¾è´Ÿæ ·æœ¬æ±  (Hard Negatives) ===
NEGATIVE_PROMPTS = [
    # Level 1: æœ€éš¾çš„å¹²æ‰° (ç”Ÿç‰©å­¦ç›¸ä¼¼)
    "Red blood cells", "Eosinophilic cytoplasm", "Stromal tissue", 
    "Extracellular matrix", "Collagen fibers", "Adipose tissue cells",
    "Blood vessel lumen",
    # Level 2: ä¼ªå½±ä¸èƒŒæ™¯
    "Tissue folds", "Air bubbles", "Glass slide background", "Blurred regions",
    # Level 3: è¯­ä¹‰é™·é˜± & é€šç”¨ç‰©ä½“
    "Mitochondria", "Golgi apparatus", "A photo of a cat", "A car"
]

def stack_dict_batched(batch):
    """è‡ªå®šä¹‰ collate_fn"""
    tensor_dict = {}
    for key, value in batch[0].items():
        if key == 'text_prompt' or key == 'name':
            tensor_dict[key] = [sample[key] for sample in batch]
        elif isinstance(value, torch.Tensor):
            tensor_dict[key] = torch.stack([sample[key] for sample in batch] )
        else:
            tensor_dict[key] = [sample[key] for sample in batch]
    return tensor_dict

class TrainingDataset(data.Dataset):
    def __init__(self, data_dir, image_size=1024, crop_size=256, mode='train', 
                 mask_num=1, requires_name=True, 
                 # ğŸ”¥ è¿™é‡ŒæŒ‡å‘ä½ ç”Ÿæˆçš„é‚£ä¸ªåŒ…å«æ‰€æœ‰å›¾ç‰‡ç»Ÿè®¡ä¿¡æ¯çš„å…¨å±€ JSON
                 dynamic_attr_path="data/MoNuSeg_SA1B/train_dynamic_instance_attributes.json"):
        
        self.data_dir = data_dir
        self.image_size = image_size
        self.crop_size = crop_size
        self.mode = mode
        
        # === 1. åŠ è½½åŠ¨æ€å±æ€§æ•°æ®åº“ (Global Stats) ===
        self.dynamic_attrs = {}
        if os.path.exists(dynamic_attr_path):
            print(f"ğŸ“– [DataLoader] Loading Dynamic Attributes from {dynamic_attr_path}...")
            with open(dynamic_attr_path, 'r') as f:
                content = json.load(f)
                # ä½ çš„ JSON ç»“æ„é‡Œï¼Œæ•°æ®æ˜¯åœ¨ "images" é”®ä¸‹
                self.dynamic_attrs = content.get("images", {})
        else:
            if mode == 'train':
                print(f"âš ï¸ [DataLoader] CRITICAL WARNING: {dynamic_attr_path} not found!")

        # === 2. æ‰«ææ–‡ä»¶ ===
        self.image_paths = []
        extensions = ['*.tif', '*.png', '*.jpg', '*.jpeg']
        for ext in extensions:
            self.image_paths.extend(glob.glob(os.path.join(data_dir, "**", ext), recursive=True))
        
        # è¿‡æ»¤æ‰ mask æ–‡ä»¶
        self.image_paths = [p for p in self.image_paths if "mask" not in p.lower()]
        
        # SA-1B æ ¼å¼æ£€æŸ¥ï¼šåªä¿ç•™æœ‰å¯¹åº”æœ¬åœ° .json çš„å›¾ç‰‡
        valid_paths = []
        for p in self.image_paths:
            # å‡è®¾ image.tif å¯¹åº” image.json
            json_path = os.path.splitext(p)[0] + ".json"
            if os.path.exists(json_path):
                valid_paths.append(p)
        
        if len(valid_paths) > 0:
            self.image_paths = valid_paths
            print(f"âœ… [DataLoader] Found {len(self.image_paths)} valid image-json pairs.")
        else:
            print(f"âš ï¸ [DataLoader] No valid pairs found! SA-1B mode requires local JSONs.")

        # === 3. å¢å¼ºç­–ç•¥ ===
        if mode == 'train':
            self.transform = A.Compose([
                A.RandomCrop(width=crop_size, height=crop_size, p=1.0),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),
                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),
                A.Resize(height=image_size, width=image_size, interpolation=cv2.INTER_LINEAR),
                ToTensorV2(),
            ])
        else:
            self.transform = A.Compose([
                # æµ‹è¯•æ—¶é€šå¸¸ CenterCrop æˆ–è€… Resize
                A.Resize(height=image_size, width=image_size, interpolation=cv2.INTER_LINEAR),
                ToTensorV2(),
            ])

    def __len__(self):
        return len(self.image_paths)

   # === ä¿®æ”¹ 1: å®æ—¶è®¡ç®—é¢ç§¯ï¼Œä¸å†ä¾èµ– JSON å­—æ®µ ===
    def decode_sa1b_mask(self, annotations, h, w, size_mode=None):
        """
        è§£ç å¹¶æ ¹æ®å¤§å°è¿‡æ»¤
        size_mode: None (å…¨éƒ¨), 'large', 'small'
        """
        mask = np.zeros((h, w), dtype=np.uint8)
        valid_pixel_count = 0
        
        for ann in annotations:
            if 'segmentation' in ann:
                seg = ann['segmentation']
                m = None
                
                # RLE
                if isinstance(seg, dict) and 'counts' in seg:
                    m = coco_mask.decode(seg)
                # Polygon
                elif isinstance(seg, list):
                    m = np.zeros((h, w), dtype=np.uint8)
                    for poly in seg:
                        pts = np.array(poly, dtype=np.int32).reshape((-1, 2))
                        cv2.fillPoly(m, [pts], 1)
                
                if m is not None:
                    # ğŸ”¥ æ ¸å¿ƒä¿®æ­£ï¼šè¿™é‡Œå®æ—¶è®¡ç®—é¢ç§¯ï¼
                    area = np.sum(m > 0)
                    
                    keep = False
                    if size_mode == 'large':
                        if area > 300: keep = True # é˜ˆå€¼
                    elif size_mode == 'small':
                        if area < 150: keep = True # é˜ˆå€¼
                    else:
                        keep = True # Generic æ¨¡å¼ï¼Œå…¨ç•™
                    
                    if keep:
                        mask[m > 0] = 1
                        valid_pixel_count += area
                    
        return mask, valid_pixel_count

    def __getitem__(self, index):
        img_path = self.image_paths[index]
        filename = os.path.basename(img_path)
        base_name = os.path.splitext(img_path)[0]
        json_path = base_name + ".json"
        
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        h, w = image.shape[:2]
        
        # è¯»å– JSON
        annotations = []
        if os.path.exists(json_path):
            try:
                with open(json_path, 'r') as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        annotations = data.get('annotations', [])
                    elif isinstance(data, list):
                        annotations = data
            except:
                pass

        # === ç­–ç•¥è°ƒæ•´ ===
        rand = random.random()
        text_prompt = "Cell nuclei"
        target_mask = np.zeros((h, w), dtype=np.uint8)
        
        # â¬‡ï¸ ä¿®æ­£ç‚¹ï¼šé™ä½è´Ÿæ ·æœ¬æ¯”ä¾‹ï¼Œåªæœ‰ 10%
        if self.mode == 'train' and rand < 0.1:
            text_prompt = random.choice(NEGATIVE_PROMPTS)
            target_mask = np.zeros((h, w), dtype=np.uint8)
            
        # â¬‡ï¸ ä¿®æ­£ç‚¹ï¼šå±æ€§è®­ç»ƒ (45%)
        elif self.mode == 'train' and rand < 0.55 and len(annotations) > 0:
            if random.random() < 0.5:
                # Large
                text_prompt = random.choice(["Large nuclei", "Tumor nuclei"])
                target_mask, px_count = self.decode_sa1b_mask(annotations, h, w, size_mode='large')
            else:
                # Small
                text_prompt = random.choice(["Small nuclei", "Lymphocyte nuclei"])
                target_mask, px_count = self.decode_sa1b_mask(annotations, h, w, size_mode='small')
            
            # ğŸ”¥ æ•‘å‘½æœºåˆ¶ï¼šå¦‚æœè¿‡æ»¤å®Œå‘ç°å…¨æ˜¯é»‘çš„ï¼ˆæ¯”å¦‚è¿™å›¾é‡Œæ ¹æœ¬æ²¡æœ‰å¤§ç»†èƒï¼‰
            # å¼ºåˆ¶å›é€€åˆ°â€œGenericâ€æ¨¡å¼ï¼Œä¸è¦è®­ç»ƒé»‘Maskï¼
            if target_mask.sum() == 0:
                text_prompt = "Cell nuclei"
                target_mask, _ = self.decode_sa1b_mask(annotations, h, w, size_mode=None)

        # â¬‡ï¸ ä¿®æ­£ç‚¹ï¼šé€šç”¨è®­ç»ƒ (45%) - æé«˜åŸºç¡€èƒ½åŠ›æƒé‡
        else:
            text_prompt = "Cell nuclei"
            target_mask, _ = self.decode_sa1b_mask(annotations, h, w, size_mode=None)
        
        # å¢å¼º
        augmented = self.transform(image=image, mask=target_mask)
        return {
            "image": augmented['image'].float(),
            "label": augmented['mask'].long().unsqueeze(0),
            "text_prompt": text_prompt,
            "name": filename.split('.')[0],
            "original_size": (self.image_size, self.image_size)
        }