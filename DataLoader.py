import os
import cv2
import json
import torch
import numpy as np
import random
import glob
from torch.utils import data
import albumentations as A
from albumentations.pytorch import ToTensorV2

try:
    from pycocotools import mask as coco_mask
except ImportError:
    print("âš ï¸ [DataLoader] pycocotools not installed! RLE decoding will FAIL.")

# === è´Ÿæ ·æœ¬æ±  ===
NEGATIVE_PROMPTS = [
    "Red blood cells", "Eosinophilic cytoplasm", "Stromal tissue", 
    "Extracellular matrix", "Collagen fibers", "Adipose tissue cells",
    "Blood vessel lumen", "Tissue folds", "Air bubbles", 
    "Glass slide background", "Mitochondria", "A photo of a cat"
]
def stack_dict_batched(batch):
    """è‡ªå®šä¹‰ collate_fn"""
    tensor_dict = {}
    for key, value in batch[0].items():
        if key == 'text_prompt' or key == 'name':
            # å­—ç¬¦ä¸²åˆ—è¡¨
            tensor_dict[key] = [sample[key] for sample in batch]
        elif isinstance(value, torch.Tensor):
            # Tensor å †å 
            tensor_dict[key] = torch.stack([sample[key] for sample in batch])
        else:
            # å…¶ä»–ç±»å‹ä½œä¸ºåˆ—è¡¨
            tensor_dict[key] = [sample[key] for sample in batch]
    return tensor_dict
class TrainingDataset(data.Dataset):
    def __init__(self, data_dir, image_size=1024, crop_size=1024, mode='train', 
                 mask_num=1, requires_name=True, 
                 # ğŸ”¥ [æ–°å¢] åŠ ä¸Šè¿™ä¸ªå‚æ•°ä»¥å…¼å®¹ train.py çš„æ—§è°ƒç”¨ï¼Œè™½ç„¶æˆ‘ä»¬ä¸ç”¨å®ƒ
                 dynamic_attr_path=None, 
                 # ä¸‹é¢ä¿æŒä¸å˜
                 stats_path="data/MoNuSeg_SA1B/dataset_stats.json",
                 prompts_path="data/MoNuSeg_SA1B/specific_prompts.json"):
        
        self.data_dir = data_dir
        self.image_size = image_size
        self.crop_size = crop_size
        self.mode = mode
        
        # === 1. åŠ è½½ç»Ÿè®¡å­¦é˜ˆå€¼ (æ•°å€¼) ===
        # é»˜è®¤å¤‡ç”¨å€¼
        self.size_thresholds = {"small_upper": 424.3, "large_lower": 731.2}
        
        if os.path.exists(stats_path):
            print(f"ğŸ“– [DataLoader] Loading Stats from {stats_path}...")
            with open(stats_path, 'r') as f:
                stats = json.load(f)
                if "thresholds" in stats:
                    self.size_thresholds = stats["thresholds"]
                    print(f"   âœ… Mask Filtering Thresholds: Small < {self.size_thresholds['small_upper']:.1f}, Large > {self.size_thresholds['large_lower']:.1f}")
        
        # === 2. åŠ è½½ä¸“ç”¨æ–‡æœ¬åº“ (è¯­ä¹‰) ===
        self.specific_library = {}
        if os.path.exists(prompts_path):
            print(f"ğŸ“– [DataLoader] Loading Specific Prompts from {prompts_path}...")
            with open(prompts_path, 'r') as f:
                self.specific_library = json.load(f)
        else:
            print(f"âš ï¸ [DataLoader] Specific prompts not found at {prompts_path}. Smart sampling disabled.")

        # === 3. æ‰«ææ–‡ä»¶ ===
        self.image_paths = []
        extensions = ['*.tif', '*.png', '*.jpg', '*.jpeg']
        for ext in extensions:
            self.image_paths.extend(glob.glob(os.path.join(data_dir, "**", ext), recursive=True))
        self.image_paths = [p for p in self.image_paths if "mask" not in p.lower()]
        
        if mode == 'train':
            # åªä¿ç•™æœ‰æ ‡æ³¨çš„å›¾
            self.image_paths = [p for p in self.image_paths if os.path.exists(os.path.splitext(p)[0] + ".json")]
            print(f"âœ… [DataLoader] Found {len(self.image_paths)} valid training images.")

        # === 4. å¢å¼ºç­–ç•¥ (Pad + Crop 1024) ===
        if mode == 'train':
            self.transform = A.Compose([
                A.PadIfNeeded(
                    min_height=crop_size, min_width=crop_size, 
                    border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0
                ),
                A.RandomCrop(width=crop_size, height=crop_size, p=1.0),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),
                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),
                A.Resize(height=image_size, width=image_size, interpolation=cv2.INTER_LINEAR),
                ToTensorV2(),
            ])
        else:
            self.transform = A.Compose([
                A.PadIfNeeded(
                    min_height=image_size, min_width=image_size, 
                    border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0
                ),
                A.Resize(height=image_size, width=image_size, interpolation=cv2.INTER_LINEAR),
                ToTensorV2(),
            ])

    def __len__(self):
        return len(self.image_paths)

    def decode_sa1b_mask(self, annotations, h, w, size_mode=None):
        """
        è§£ç å¹¶è¿‡æ»¤ï¼š
        - ç¬¦åˆæ¡ä»¶çš„ -> Label 1
        - ä¸ç¬¦åˆæ¡ä»¶çš„ï¼ˆä½†ç¡®æ˜¯ä¸€ä¸ªç»†èƒï¼‰ -> Label 255 (Ignore)
        - çœŸæ­£çš„èƒŒæ™¯ -> Label 0
        """
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # ä½¿ç”¨åŠ è½½çš„ç»Ÿè®¡å­¦é˜ˆå€¼
        small_thresh = self.size_thresholds['small_upper']
        large_thresh = self.size_thresholds['large_lower']
        
        for ann in annotations:
            if 'segmentation' not in ann: continue
            
            # è§£ç å•ä¸ª Mask
            m = None
            if isinstance(ann['segmentation'], dict) and 'counts' in ann['segmentation']:
                m = coco_mask.decode(ann['segmentation'])
            elif isinstance(ann['segmentation'], list):
                m = np.zeros((h, w), dtype=np.uint8)
                for poly in ann['segmentation']:
                    pts = np.array(poly, dtype=np.int32).reshape((-1, 2))
                    cv2.fillPoly(m, [pts], 1)
            
            if m is not None:
                area = np.sum(m > 0)
                
                # åˆ¤æ–­é€»è¾‘
                is_target = False
                is_ignore = False
                
                if size_mode == 'large':
                    if area > large_thresh: is_target = True
                    else: is_ignore = True # æ˜¯ç»†èƒï¼Œä½†å¤ªå°ï¼Œå¿½ç•¥
                elif size_mode == 'small':
                    if area < small_thresh: is_target = True
                    else: is_ignore = True # æ˜¯ç»†èƒï¼Œä½†å¤ªå¤§ï¼Œå¿½ç•¥
                else:
                    is_target = True # Generic æ¨¡å¼å…¨éƒ½è¦
                
                # èµ‹å€¼ (æ³¨æ„è¦†ç›–é¡ºåº)
                if is_target:
                    mask[m > 0] = 1
                elif is_ignore:
                    # åªæœ‰åœ¨è¿˜æ²¡è¢«æ ‡è®°ä¸º Target çš„åœ°æ–¹æ‰æ ‡è®° Ignore (é˜²æ­¢é‡å è¦†ç›–)
                    mask[(m > 0) & (mask == 0)] = 255
                    
        return mask

    def __getitem__(self, index):
        img_path = self.image_paths[index]
        filename = os.path.basename(img_path)
        key_name = filename.replace(".tif", "").replace(".png", "") # ç”¨äºæŸ¥è¡¨
        json_path = os.path.splitext(img_path)[0] + ".json"
        
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        h, w = image.shape[:2]
        
        # 1. è¯»å–æ ‡æ³¨
        annotations = []
        try:
            with open(json_path, 'r') as f:
                data = json.load(f)
                annotations = data.get('annotations', []) if isinstance(data, dict) else data
        except: pass

        # 2. æŸ¥é˜…ä¸“ç”¨æ–‡æœ¬åº“
        # è·å–è¯¥å›¾çš„ä¸“å±æè¿° (å¦‚æœæŸ¥ä¸åˆ°å°±ç”¨é»˜è®¤å€¼)
        img_info = self.specific_library.get(filename, self.specific_library.get(key_name, {}))
        
        specific_prompt_text = img_info.get("prompt", "Microscopic image of cell nuclei.")
        img_attrs = img_info.get("attributes", {}) # {'size': 'large', ...}
        
        # === ğŸ”¥ æ™ºèƒ½é‡‡æ ·é€»è¾‘ ===
        rand = random.random()
        text_prompt = "Cell nuclei"
        target_mask = np.zeros((h, w), dtype=np.uint8)
        
        # ğŸŒ‘ Task A: è´Ÿæ ·æœ¬ (10%)
        if self.mode == 'train' and rand < 0.1:
            text_prompt = random.choice(NEGATIVE_PROMPTS)
            target_mask = np.zeros((h, w), dtype=np.uint8)
            
        # ğŸŒ• Task B: å±æ€§ç‰¹å®šä»»åŠ¡ (45%)
        # æ ¹æ® specific_prompts.json é‡Œçš„æ ‡ç­¾æ¥å†³å®šç»ƒä»€ä¹ˆ
        elif self.mode == 'train' and rand < 0.55:
            img_size_tag = img_attrs.get("size", "medium")
            
            # å¦‚æœè¿™å¼ å›¾æœ¬èº«å°±æ˜¯ largeï¼Œé‚£æˆ‘ä»¬å¤§æ¦‚ç‡ç»ƒ Large ä»»åŠ¡
            if img_size_tag == "large" and random.random() < 0.8:
                text_prompt = random.choice(["Large nuclei", "Tumor nuclei"])
                target_mask = self.decode_sa1b_mask(annotations, h, w, size_mode='large')
            
            # å¦‚æœè¿™å¼ å›¾æ˜¯ smallï¼Œå¤§æ¦‚ç‡ç»ƒ Small ä»»åŠ¡
            elif img_size_tag == "small" and random.random() < 0.8:
                text_prompt = random.choice(["Small nuclei", "Lymphocyte nuclei"])
                target_mask = self.decode_sa1b_mask(annotations, h, w, size_mode='small')
            
            # å¦åˆ™ (medium æˆ– æ²¡å‘½ä¸­æ¦‚ç‡)ï¼Œç»ƒé€šç”¨ä»»åŠ¡
            else:
                text_prompt = "Cell nuclei"
                target_mask = self.decode_sa1b_mask(annotations, h, w, size_mode=None)
            
            # å…œåº•ï¼šå¦‚æœè¿‡æ»¤å®ŒMaskæ˜¯å…¨é»‘çš„ï¼Œå¼ºåˆ¶å›é€€åˆ° Context Task
            if target_mask.sum() == 0:
                text_prompt = specific_prompt_text # ä½¿ç”¨ç”Ÿæˆçš„é•¿æ–‡æœ¬
                target_mask = self.decode_sa1b_mask(annotations, h, w, size_mode=None)

        # ğŸŒŸ Task C: ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä»»åŠ¡ (45%)
        # ä½¿ç”¨ç”Ÿæˆçš„é•¿æ–‡æœ¬ï¼š"Microscopic image of large, round nuclei..."
        else:
            text_prompt = specific_prompt_text
            target_mask = self.decode_sa1b_mask(annotations, h, w, size_mode=None)
        
        # å¢å¼º
        augmented = self.transform(image=image, mask=target_mask)
        return {
            "image": augmented['image'].float(),
            "label": augmented['mask'].long().unsqueeze(0),
            "text_prompt": text_prompt,
            "name": filename.split('.')[0],
            "original_size": (self.image_size, self.image_size)
        }