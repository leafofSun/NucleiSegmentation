import os
import cv2
import json
import torch
import numpy as np
import glob
import random
from torch.utils import data
import albumentations as A
from albumentations.pytorch import ToTensorV2
from skimage.measure import label, regionprops

try:
    from pycocotools import mask as coco_mask
except ImportError:
    pass

try:
    from sklearn.neighbors import KDTree
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ Warning: sklearn not available. Arrangement analysis will use simplified method.")

# === å…¨å±€ ID æ˜ å°„è¡¨ ===
ORGAN_TO_ID = {
    "Kidney": 0, "Breast": 1, "Prostate": 2, "Lung": 3, 
    "Colon": 4, "Stomach": 5, "Liver": 6, "Bladder": 7, 
    "Brain": 8, "Generic": 9
}

def stack_dict_batched(batch):
    """è‡ªå®šä¹‰ Collate Function"""
    tensor_dict = {}
    for key, value in batch[0].items():
        if isinstance(value, torch.Tensor):
            tensor_dict[key] = torch.stack([sample[key] for sample in batch])
        elif isinstance(value, (int, float, str)):
            tensor_dict[key] = [sample[key] for sample in batch]
        else:
            tensor_dict[key] = [sample[key] for sample in batch]
    return tensor_dict

# ğŸ”¥ [ä¿®æ”¹] 5ç»´å±æ€§åˆ†æå™¨ (æ”¯æŒé¢ç§¯ç¼©æ”¾)
def analyze_comprehensive_attributes(image, mask, area_scale=1.0):
    """
    è®¡ç®— PromptNu å®šä¹‰çš„ 5 ä¸ªç»´åº¦çš„å±æ€§ã€‚
    ğŸ”¥ [æ ¸å¿ƒä¿®æ­£] å¼•å…¥ area_scaleï¼Œè§£å†³ Crop->Resize å¯¼è‡´çš„é¢ç§¯è†¨èƒ€é—®é¢˜ã€‚
    
    Args:
        area_scale (float): é¢ç§¯ç¼©æ”¾å€æ•°ã€‚ä¾‹å¦‚ 256->1024 æ”¾å¤§æ—¶ï¼ŒScale=16.0ã€‚
    """
    # é»˜è®¤è¿”å›å€¼
    default_visuals = {
        "color": "deep-purple stained", "shape": "round", "arrangement": "uniform",
        "size": "medium", "density": "moderate"
    }
    default_labels = [0, 0, 0, 1, 1]

    if mask.sum() == 0:
        return default_visuals, default_labels

    labeled_mask = label(mask)
    regions = regionprops(labeled_mask)
    
    if not regions:
        return default_visuals, default_labels

    # === 1. å¤§å° (Size) [0: Small, 1: Medium, 2: Large] ===
    # åŸå§‹é˜ˆå€¼: Small < 250, Large > 600
    # ğŸ”¥ åŠ¨æ€è°ƒæ•´é˜ˆå€¼ï¼šä¹˜ä»¥é¢ç§¯ç¼©æ”¾å€æ•°
    th_small = 250.0 * area_scale
    th_large = 600.0 * area_scale

    areas = np.array([r.area for r in regions])
    mean_area = np.mean(areas)
    
    if mean_area < th_small:
        size_lbl, size_txt = 0, "small"
    elif mean_area > th_large:
        size_lbl, size_txt = 2, "large"
    else:
        size_lbl, size_txt = 1, "medium"

    # === 2. å½¢çŠ¶ (Shape) [ç¼©æ”¾ä¸å˜] ===
    eccs = np.array([r.eccentricity for r in regions])
    mean_ecc = np.mean(eccs)
    if mean_ecc < 0.6:
        shape_lbl, shape_txt = 0, "round"
    elif mean_ecc < 0.85:
        shape_lbl, shape_txt = 1, "oval"
    else:
        shape_lbl, shape_txt = 2, "elongated/irregular"

    # === 3. å¯†åº¦ (Density) [ä½¿ç”¨è¦†ç›–ç‡ï¼Œç¼©æ”¾ä¸å˜] ===
    img_area = mask.shape[0] * mask.shape[1]
    coverage = np.sum(areas) / img_area
    if coverage < 0.05:
        den_lbl, den_txt = 0, "sparsely distributed"
    elif coverage > 0.20:
        den_lbl, den_txt = 2, "densely packed"
    else:
        den_lbl, den_txt = 1, "moderately distributed"

    # === 4. æ’åˆ— (Arrangement) [ç›¸å¯¹è·ç¦» CVï¼Œç¼©æ”¾ä¸å˜] ===
    centroids = np.array([r.centroid for r in regions])
    if len(centroids) > 5:
        if SKLEARN_AVAILABLE:
            try:
                tree = KDTree(centroids)
                dists, _ = tree.query(centroids, k=2)
                nn_dists = dists[:, 1]
                dist_cv = np.std(nn_dists) / (np.mean(nn_dists) + 1e-6)
                if dist_cv > 0.6:
                    arr_lbl, arr_txt = 1, "disordered/clustered"
                else:
                    arr_lbl, arr_txt = 0, "uniformly arranged"
            except:
                arr_lbl, arr_txt = 0, "uniformly arranged"
        else:
            # ç®€åŒ–æ–¹æ³•
            centroid_std = np.std(centroids, axis=0).mean()
            # è¿™é‡Œçš„ 0.3 æ˜¯ä¸ªç»éªŒç›¸å¯¹å€¼ï¼Œå¤§è‡´ç¨³å¥
            if centroid_std > np.mean(centroids) * 0.3:
                arr_lbl, arr_txt = 1, "disordered/clustered"
            else:
                arr_lbl, arr_txt = 0, "uniformly arranged"
    else:
        arr_lbl, arr_txt = 0, "isolated"

    # === 5. é¢œè‰² (Color) [ç¼©æ”¾ä¸å˜] ===
    if image is not None and image.size > 0:
        mask_bool = mask > 0
        if mask_bool.sum() > 0:
            if len(image.shape) == 3:
                masked_pixels = image[mask_bool]
                mean_brightness = np.mean(masked_pixels)
                if mean_brightness > 200:
                    col_lbl, col_txt = 1, "pink/light stained"
                else:
                    col_lbl, col_txt = 0, "deep-purple stained"
            else:
                col_lbl, col_txt = 0, "deep-purple stained"
        else:
            col_lbl, col_txt = 0, "deep-purple stained"
    else:
        col_lbl, col_txt = 0, "deep-purple stained"

    visuals = {
        "color": col_txt, "shape": shape_txt, "arrangement": arr_txt,
        "size": size_txt, "density": den_txt
    }
    attr_labels = [col_lbl, shape_lbl, arr_lbl, size_lbl, den_lbl]
    
    return visuals, attr_labels

# ğŸ”¥ [æ–°å¢] è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆæ¤­åœ†é«˜æ–¯çƒ­åŠ›å›¾
def generate_elliptical_heatmap(mask, image_size=(1024, 1024), sigma_scale=0.25):
    """
    æ ¹æ® Mask ç”Ÿæˆ Variable Ellipse Gaussian Heatmap.
    """
    heatmap = np.zeros(image_size, dtype=np.float32)
    labeled_mask = label(mask)
    regions = regionprops(labeled_mask)
    
    for region in regions:
        if region.area < 10: continue 
        
        y0, x0 = region.centroid
        orientation = region.orientation
        major = region.major_axis_length
        minor = region.minor_axis_length
        
        sigma_x = max(1.0, major * sigma_scale)
        sigma_y = max(1.0, minor * sigma_scale)
        
        theta = -orientation
        cos_t = np.cos(theta)
        sin_t = np.sin(theta)
        
        cos2, sin2 = cos_t**2, sin_t**2
        a = cos2 / (2 * sigma_x**2) + sin2 / (2 * sigma_y**2)
        b = -np.sin(2 * theta) / (4 * sigma_x**2) + np.sin(2 * theta) / (4 * sigma_y**2)
        c = sin2 / (2 * sigma_x**2) + cos2 / (2 * sigma_y**2)
        
        bb_size = int(max(major, minor) * 1.5)
        y_min, y_max = max(0, int(y0 - bb_size)), min(image_size[0], int(y0 + bb_size + 1))
        x_min, x_max = max(0, int(x0 - bb_size)), min(image_size[1], int(x0 + bb_size + 1))
        
        if x_max <= x_min or y_max <= y_min: continue

        xx, yy = np.meshgrid(np.arange(x_min, x_max), np.arange(y_min, y_max))
        dx = xx - x0
        dy = yy - y0
        
        gaussian = np.exp(-(a * dx**2 + 2 * b * dx * dy + c * dy**2))
        heatmap[y_min:y_max, x_min:x_max] = np.maximum(heatmap[y_min:y_max, x_min:x_max], gaussian)
        
    return heatmap

class TrainingDataset(data.Dataset):
    def __init__(self, 
                 data_dir, 
                 knowledge_path=None, 
                 image_size=1024, # æ¨¡å‹è¾“å…¥å°ºå¯¸
                 crop_size=256,   # ğŸ”¥ [ä¿®æ”¹] ç‰©ç†åˆ‡ç‰‡å°ºå¯¸ (é»˜è®¤æ¨è 256)
                 mode='train',
                 prompt_mode='dynamic'):
        
        self.data_dir = data_dir
        self.image_size = image_size
        self.patch_size = crop_size # é‡å‘½åä¸º patch_size ä»¥ç¤ºåŒºåˆ«
        self.mode = mode
        self.organ_to_id = ORGAN_TO_ID
        self.prompt_mode = prompt_mode
        
        # === 1. åŠ è½½æ˜¾å¼çŸ¥è¯†åº“ ===
        self.knowledge_base = {}
        if knowledge_path and os.path.exists(knowledge_path):
            print(f"ğŸ“– [DataLoader] Loading Knowledge Base from: {knowledge_path}")
            with open(knowledge_path, 'r') as f:
                self.knowledge_base = json.load(f)
        else:
            if mode == 'train':
                print(f"âš ï¸ [DataLoader] Warning: Knowledge path not found! Defaults will be used.")

        # === 2. æ‰«ææ•°æ® ===
        self.image_paths = []
        extensions = ['*.tif', '*.png', '*.jpg', '*.jpeg']
        for ext in extensions:
            self.image_paths.extend(glob.glob(os.path.join(data_dir, "**", ext), recursive=True))
        
        self.image_paths = [p for p in self.image_paths if "mask" not in p.lower()]
        
        if mode == 'train':
            valid_paths = []
            for p in self.image_paths:
                json_p = os.path.splitext(p)[0] + ".json"
                if not os.path.exists(json_p):
                     json_p = p.rsplit('.', 1)[0] + ".json"
                
                if os.path.exists(json_p):
                    valid_paths.append(p)
            self.image_paths = valid_paths
            print(f"âœ… [DataLoader] Initialized with {len(self.image_paths)} images (Mode: {mode})")

        # === 3. å¢å¼ºç­–ç•¥ (æ ¸å¿ƒä¿®æ­£) ===
        if mode == 'train':
            self.transform = A.Compose([
                # 1. ç‰©ç†è£å‰ª: å…ˆè£å‡º 256x256 (æˆ–ä¼ å…¥çš„ crop_size)
                A.PadIfNeeded(min_height=self.patch_size, min_width=self.patch_size, border_mode=cv2.BORDER_CONSTANT, value=0),
                A.RandomCrop(width=self.patch_size, height=self.patch_size, p=1.0),
                
                # 2. å‡ ä½•å¢å¼º
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),
                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),
                
                # 3. ğŸ”¥ æ”¾å¤§å› 1024 ä»¥é€‚é… SAM é¢„è®­ç»ƒåˆ†è¾¨ç‡
                A.Resize(height=image_size, width=image_size, interpolation=cv2.INTER_LINEAR),
                ToTensorV2(),
            ])
        else:
            # éªŒè¯/æµ‹è¯•é›†é€šå¸¸ä¸åœ¨æ­¤ Resizeï¼Œè€Œæ˜¯äº¤ç”± Sliding Window å¤„ç†
            # æˆ–è€…ä¿æŒåŸå›¾å°ºå¯¸è¾“å‡º
            self.transform = A.Compose([
                A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT, value=0),
                # éªŒè¯é›†å¦‚æœä¸æ˜¯æ»‘åŠ¨çª—å£ï¼Œå¯ä»¥åœ¨è¿™é‡Œ resizeï¼Œä½†å»ºè®®åœ¨ train.py ç”¨æ»‘åŠ¨çª—å£
                # A.Resize(height=image_size, width=image_size), 
                ToTensorV2(),
            ])

    def __len__(self):
        return len(self.image_paths)

    def decode_mask(self, json_path, h, w):
        mask = np.zeros((h, w), dtype=np.uint8)
        try:
            with open(json_path, 'r') as f:
                data = json.load(f)
            annotations = data.get('annotations', []) if isinstance(data, dict) else data
            
            for ann in annotations:
                if 'segmentation' not in ann: continue
                seg = ann['segmentation']
                
                if isinstance(seg, list):
                    for poly in seg:
                        pts = np.array(poly, dtype=np.int32).reshape((-1, 2))
                        cv2.fillPoly(mask, [pts], 1)
                elif isinstance(seg, dict):
                    m = coco_mask.decode(seg)
                    mask[m > 0] = 1
        except:
            pass
        return mask

    def __getitem__(self, index):
        img_path = self.image_paths[index]
        filename = os.path.basename(img_path)
        
        # 1. è¯»å›¾
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        h, w = image.shape[:2]
        
        # 2. è¯»åŸå§‹ GT Mask
        target_mask = np.zeros((h, w), dtype=np.uint8)
        json_path = os.path.splitext(img_path)[0] + ".json"
        if not os.path.exists(json_path):
             json_path = img_path.rsplit('.', 1)[0] + ".json"
             
        if os.path.exists(json_path):
            target_mask = self.decode_mask(json_path, h, w)

        # 3. å¢å¼º (Crop -> Augment -> Resize)
        augmented = self.transform(image=image, mask=target_mask)
        img_tensor = augmented['image'].float()
        
        # è½¬å› numpy è¿›è¡Œç‰©ç†åˆ†æ
        aug_mask_np = augmented['mask'].numpy() 
        if aug_mask_np.ndim == 3: aug_mask_np = aug_mask_np[0]
        aug_mask_np = aug_mask_np.astype(np.uint8)

        # ============================================================
        # ğŸ”¥ è®¡ç®—é¢ç§¯ç¼©æ”¾å› å­ (Area Scale Factor)
        # ============================================================
        if self.mode == 'train':
            # ä¾‹å¦‚: (1024 / 256)^2 = 16.0
            scale_linear = self.image_size / self.patch_size
            area_scale = scale_linear ** 2
        else:
            area_scale = 1.0

        # ============================================================
        # ğŸ”¥ åŠ¨æ€ä»»åŠ¡ç”Ÿæˆ & ç‰©ç†è¿‡æ»¤
        # ============================================================
        task_type = "generic"
        text_prompt = "Cell nuclei"
        active_mask = aug_mask_np.copy()
        
        kb_entry = self.knowledge_base.get(filename, {})
        organ_name = kb_entry.get("organ_id", "Generic")
        organ_id = self.organ_to_id.get(organ_name, 9)
        attribute_text = kb_entry.get("text_prompt", "Microscopic image of cell nuclei.")

        labeled_mask = label(aug_mask_np)
        regions = regionprops(labeled_mask)

        # ä»…åœ¨è®­ç»ƒæ¨¡å¼ä¸”æœ‰ç»†èƒæ—¶è¿›è¡ŒåŠ¨æ€é‡‡æ ·
        if self.mode == 'train' and self.prompt_mode == 'dynamic' and len(regions) > 5:
            areas = np.array([r.area for r in regions])
            min_a, max_a = np.min(areas), np.max(areas)
            
            is_diverse = (max_a > min_a * 2.0)
            rand_p = random.random()
            
            if rand_p < 0.5 or not is_diverse:
                task_type = "generic"
                text_prompt = "Cell nuclei"
                
            elif rand_p < 0.75:
                # === æ‰¾å¤§ç»†èƒ (Large) ===
                task_type = "large"
                text_prompt = "Large, pleomorphic tumor nuclei"
                # åŠ¨æ€é˜ˆå€¼ (Percentile è‡ªåŠ¨é€‚åº”æ”¾å¤§åçš„é¢ç§¯åˆ†å¸ƒ)
                th_high = np.percentile(areas, 67)
                active_mask = np.zeros_like(aug_mask_np)
                
                valid_count = 0
                for r in regions:
                    if r.area >= th_high:
                        active_mask[labeled_mask == r.label] = 1
                        valid_count += 1
                
                if valid_count == 0:
                    task_type = "generic"
                    text_prompt = "Cell nuclei"
                    active_mask = aug_mask_np.copy()
            
            else:
                # === æ‰¾å°ç»†èƒ (Small) ===
                task_type = "small"
                text_prompt = "Small, round lymphocyte nuclei"
                th_low = np.percentile(areas, 33)
                active_mask = np.zeros_like(aug_mask_np)
                
                valid_count = 0
                for r in regions:
                    if r.area <= th_low and r.eccentricity < 0.9:
                        active_mask[labeled_mask == r.label] = 1
                        valid_count += 1
                
                if valid_count == 0:
                    task_type = "generic"
                    text_prompt = "Cell nuclei"
                    active_mask = aug_mask_np.copy()

        # ============================================================
        
        # 4. ğŸ”¥ ç‰©ç†è®¡ç®— (ä¼ å…¥ area_scale è¿›è¡Œä¿®æ­£)
        img_for_analysis = img_tensor.permute(1, 2, 0).numpy()
        if img_for_analysis.max() <= 1.0:
            img_for_analysis = (img_for_analysis * 255).astype(np.uint8)
        else:
            img_for_analysis = img_for_analysis.astype(np.uint8)
        
        visuals, attr_labels_list = analyze_comprehensive_attributes(
            img_for_analysis,
            active_mask,
            area_scale=area_scale  # ğŸ”¥ å…³é”®ä¿®æ­£
        )
        
        attr_labels_tensor = torch.tensor(attr_labels_list).long()
        
        # 5. æ„é€ èåˆ Prompt
        full_prompt = (f"Microscopic view of {visuals['density']}, {visuals['size']} nuclei, "
                      f"{visuals['arrangement']}, with {visuals['shape']} features.")
        
        if task_type == "generic":
            text_prompt = full_prompt
        else:
            text_prompt = f"{text_prompt} ({visuals['density']}, {visuals['arrangement']})"
        
        # 6. å°è£…è¿”å›æ•°æ®
        label_tensor = torch.from_numpy(active_mask).long().unsqueeze(0)
        
        # ç”Ÿæˆæ¤­åœ†çƒ­åŠ›å›¾ (åŸºäº Resize åçš„ Mask)
        gt_heatmap = generate_elliptical_heatmap(active_mask, image_size=(self.image_size, self.image_size))
        heatmap_tensor = torch.from_numpy(gt_heatmap).float().unsqueeze(0)
        
        # Prompt Dropout
        if self.mode == 'train' and random.random() < 0.2:
            organ_id = 9 # Generic

        return {
            "image": img_tensor,
            "label": label_tensor,         # [1, 1024, 1024]
            "gt_heatmap": heatmap_tensor,  # [1, 1024, 1024]
            
            "organ_id": organ_id,
            "attribute_text": attribute_text,
            "text_prompt": text_prompt,
            
            "attr_labels": attr_labels_tensor, # [5] ç›‘ç£ä¿¡å·
            
            "name": filename,
            "original_size": (self.image_size, self.image_size),
            "task_type": task_type
        }