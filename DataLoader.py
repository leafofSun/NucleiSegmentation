import os
import cv2
import json
import torch
import numpy as np
import random
from torch.utils import data
import albumentations as A
from albumentations.pytorch import ToTensorV2
from skimage.measure import label, regionprops
from dataclasses import dataclass

# === å¯é€‰ä¾èµ– ===
try:
    from sklearn.neighbors import KDTree
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# ==============================================================================
# 1. åŠ¨æ€é…ç½®ç±» (æ•°æ®é©±åŠ¨çš„æ ¸å¿ƒ)
# ==============================================================================
@dataclass
class AttributeConfig:
    """
    ç‰©ç†å±æ€§åˆ†æçš„é˜ˆå€¼é…ç½®ã€‚
    è¿™äº›å€¼ä¸å†å†™æ­»ï¼Œè€Œæ˜¯ä» medical_knowledge.json çš„å…ƒæ•°æ®ä¸­åŠ¨æ€åŠ è½½ã€‚
    """
    # é»˜è®¤å…œåº•å€¼ (ä»…åœ¨è¯»å–å…ƒæ•°æ®å¤±è´¥æ—¶ä½¿ç”¨)
    AREA_SMALL: float = 250.0
    AREA_LARGE: float = 600.0
    DENSITY_SPARSE: float = 0.05
    DENSITY_DENSE: float = 0.20
    
    # å‡ ä½•å¸¸æ•° (é€šå¸¸ä¸éœ€è¦å˜åŠ¨)
    SHAPE_ROUND: float = 0.6
    SHAPE_OVAL: float = 0.85
    ARRANGE_CLUMPED: float = 0.6
    COLOR_BRIGHT: float = 200.0

    @classmethod
    def from_metadata(cls, stats):
        """å·¥å‚æ–¹æ³•ï¼šä»ç»Ÿè®¡æ•°æ®æ„å»ºé…ç½®"""
        if not stats:
            return cls()
        
        print(f"ğŸ“Š [Config] Initializing thresholds from Dataset Statistics...")
        return cls(
            AREA_SMALL=stats.get('th_size_small', 250.0),
            AREA_LARGE=stats.get('th_size_large', 600.0),
            DENSITY_SPARSE=stats.get('th_dens_sparse', 0.05),
            DENSITY_DENSE=stats.get('th_dens_dense', 0.20)
        )

# ==============================================================================
# 2. ç‰©ç†å±æ€§åˆ†æå™¨ (æ— çŠ¶æ€å‡½æ•°)
# ==============================================================================
def analyze_physical_attributes(image, mask, config: AttributeConfig, area_scale=1.0):
    """
    è®¡ç®— PromptNu å®šä¹‰çš„ 5 ä¸ªç»´åº¦çš„å±æ€§ã€‚
    
    Args:
        config: åŒ…å«åŠ¨æ€é˜ˆå€¼çš„é…ç½®å¯¹è±¡
        area_scale: é¢ç§¯ç¼©æ”¾å› å­ (ç”¨äºä¿®æ­£ Resize å¸¦æ¥çš„é¢ç§¯å˜åŒ–)
    """
    # é»˜è®¤è¿”å›å€¼
    results = {
        "visuals": {"color": "deep-purple stained", "shape": "round", "arrangement": "uniform", "size": "medium", "density": "moderate"},
        "labels": [0, 0, 0, 1, 1] 
    }

    if mask.sum() == 0: return results

    labeled_mask = label(mask)
    regions = regionprops(labeled_mask)
    if not regions: return results

    # --- 1. å¤§å° (Size) ---
    # æ ¸å¿ƒé€»è¾‘ï¼šåŸºå‡†é˜ˆå€¼ * ç¼©æ”¾å› å­
    #
    th_small = config.AREA_SMALL * area_scale
    th_large = config.AREA_LARGE * area_scale
    
    areas = np.array([r.area for r in regions])
    mean_area = np.mean(areas)
    
    if mean_area < th_small:
        size_lbl, size_txt = 0, "small"
    elif mean_area > th_large:
        size_lbl, size_txt = 2, "large, enlarged"
    else:
        size_lbl, size_txt = 1, "medium-sized"

    # --- 2. å½¢çŠ¶ (Shape) ---
    eccs = np.array([r.eccentricity for r in regions])
    mean_ecc = np.mean(eccs)
    if mean_ecc < config.SHAPE_ROUND:
        shape_lbl, shape_txt = 0, "round"
    elif mean_ecc < config.SHAPE_OVAL:
        shape_lbl, shape_txt = 1, "oval"
    else:
        shape_lbl, shape_txt = 2, "elongated"

    # --- 3. å¯†åº¦ (Density) ---
    # å¯†åº¦è®¡ç®—ä¸å— Resize å½±å“å¤ªæ˜æ˜¾ (å› ä¸ºæ˜¯æ¯”ä¾‹æˆ–æ•°é‡)ï¼Œä½†åœ¨ Crop åéœ€è¦é‡æ–°è¯„ä¼°
    count = len(regions)
    # æ³¨æ„ï¼šè¿™é‡Œçš„é˜ˆå€¼æ˜¯åŸºäºå®Œæ•´åˆ‡ç‰‡çš„ç»Ÿè®¡ã€‚å¦‚æœæ˜¯ RandomCropï¼Œå¯†åº¦å¯èƒ½ä¼šæ³¢åŠ¨ã€‚
    # æˆ‘ä»¬è¿™é‡Œå‡è®¾ Crop åçš„å¯†åº¦ä¸åŸå›¾å±€éƒ¨å¯†åº¦æ­£ç›¸å…³ã€‚
    if count < config.DENSITY_SPARSE: # è¿™é‡Œçš„é˜ˆå€¼å¯èƒ½éœ€è¦æ ¹æ® crop_size/orig_size æ¯”ä¾‹å¾®è°ƒï¼Œæš‚æ—¶ä¿æŒåŸé€»è¾‘
        den_lbl, den_txt = 0, "sparsely distributed"
    elif count > config.DENSITY_DENSE:
        den_lbl, den_txt = 2, "densely packed"
    else:
        den_lbl, den_txt = 1, "moderately distributed"

    # --- 4. æ’åˆ— (Arrangement) ---
    centroids = np.array([r.centroid for r in regions])
    if len(centroids) > 5 and SKLEARN_AVAILABLE:
        try:
            tree = KDTree(centroids)
            dists, _ = tree.query(centroids, k=2)
            nn_dists = dists[:, 1]
            dist_cv = np.std(nn_dists) / (np.mean(nn_dists) + 1e-6)
            if dist_cv > config.ARRANGE_CLUMPED:
                arr_lbl, arr_txt = 1, "disordered/clustered"
            else:
                arr_lbl, arr_txt = 0, "uniformly arranged"
        except:
            arr_lbl, arr_txt = 0, "uniformly arranged"
    else:
        arr_lbl, arr_txt = 0, "isolated"

    # --- 5. é¢œè‰² (Color) ---
    col_lbl, col_txt = 0, "deep-purple stained"
    if image is not None:
        masked_pixels = image[mask > 0]
        if masked_pixels.size > 0:
            if np.mean(masked_pixels) > config.COLOR_BRIGHT:
                col_lbl, col_txt = 1, "pink/light stained"

    return {
        "visuals": {"color": col_txt, "shape": shape_txt, "arrangement": arr_txt, "size": size_txt, "density": den_txt},
        "labels": [col_lbl, shape_lbl, arr_lbl, size_lbl, den_lbl]
    }

def generate_elliptical_heatmap(mask, image_size=(1024, 1024), sigma_scale=0.25):
    """ç”Ÿæˆæ¤­åœ†é«˜æ–¯çƒ­åŠ›å›¾"""
    heatmap = np.zeros(image_size, dtype=np.float32)
    labeled_mask = label(mask)
    regions = regionprops(labeled_mask)
    
    for region in regions:
        if region.area < 5: continue
        y0, x0 = region.centroid
        major, minor = region.major_axis_length, region.minor_axis_length
        theta = -region.orientation
        
        sigma_x = max(1.0, major * sigma_scale)
        sigma_y = max(1.0, minor * sigma_scale)
        
        # ä¼˜åŒ–ï¼šåªåœ¨ Bounding Box å†…è®¡ç®—é«˜æ–¯ï¼Œå¤§å¹…åŠ é€Ÿ
        bb_size = int(max(major, minor) * 1.5)
        y_min, y_max = max(0, int(y0 - bb_size)), min(image_size[0], int(y0 + bb_size + 1))
        x_min, x_max = max(0, int(x0 - bb_size)), min(image_size[1], int(x0 + bb_size + 1))
        
        if x_max <= x_min or y_max <= y_min: continue

        xx, yy = np.meshgrid(np.arange(x_min, x_max), np.arange(y_min, y_max))
        dx, dy = xx - x0, yy - y0
        
        cos_t, sin_t = np.cos(theta), np.sin(theta)
        a = (cos_t**2)/(2*sigma_x**2) + (sin_t**2)/(2*sigma_y**2)
        b = -(np.sin(2*theta))/(4*sigma_x**2) + (np.sin(2*theta))/(4*sigma_y**2)
        c = (sin_t**2)/(2*sigma_x**2) + (cos_t**2)/(2*sigma_y**2)
        
        gaussian = np.exp(-(a*dx**2 + 2*b*dx*dy + c*dy**2))
        heatmap[y_min:y_max, x_min:x_max] = np.maximum(heatmap[y_min:y_max, x_min:x_max], gaussian)
        
    return heatmap

# ==============================================================================
# 3. é€šç”¨æ•°æ®é›†ç±» (Universal Dataset)
# ==============================================================================
class UniversalDataset(data.Dataset):
    def __init__(self, 
                 data_root, 
                 knowledge_path,  # ğŸ”¥ å¿…é¡»æä¾›ç”Ÿæˆå¥½çš„ knowledge.json
                 image_size=1024, 
                 crop_size=256,   
                 mode='train',
                 prompt_mode='dynamic'):
        
        self.data_root = data_root
        self.image_size = image_size
        self.crop_size = crop_size
        self.mode = mode
        self.prompt_mode = prompt_mode
        
        # === 1. åŠ è½½çŸ¥è¯†åº“ (å«å…ƒæ•°æ®) ===
        print(f"ğŸ“– [DataLoader] Loading Knowledge Base: {knowledge_path}")
        with open(knowledge_path, 'r') as f:
            self.full_db = json.load(f)
            
        # === 2. æå–å…¨å±€ç»Ÿè®¡ -> åˆå§‹åŒ–é…ç½® ===
        if "__meta__" in self.full_db:
            meta = self.full_db.pop("__meta__") # å¼¹å‡ºå…ƒæ•°æ®
            stats = meta.get("stats", {})
            self.attr_config = AttributeConfig.from_metadata(stats)
            # ä½ ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œè¯»å– taxonomy æ¥æ„å»º organ_mapï¼Œä½†æˆ‘ä»¬å·²ç»åœ¨æ ·æœ¬é‡Œå­˜äº† organ_idx
        else:
            print("âš ï¸ [DataLoader] Warning: '__meta__' not found via Knowledge Base. Using default thresholds.")
            self.attr_config = AttributeConfig()

        # === 3. æ„å»ºæ ·æœ¬åˆ—è¡¨ ===
        self.samples = []
        skipped = 0
        
        for rel_path, entry in self.full_db.items():
            # è¿‡æ»¤ Split (train/test)
            if entry.get('split') != mode:
                skipped += 1
                continue
                
            # æ„å»ºè·¯å¾„ (å‡è®¾çŸ¥è¯†åº“é‡Œçš„ Key æ˜¯ç›¸å¯¹è·¯å¾„)
            full_img_path = os.path.join(data_root, rel_path)
            full_json_path = full_img_path.replace(".png", ".json")
            
            if os.path.exists(full_img_path) and os.path.exists(full_json_path):
                self.samples.append({
                    "img_path": full_img_path,
                    "json_path": full_json_path,
                    "data": entry # åŒ…å« prompt, organ_idx, visual_stats
                })
        
        print(f"âœ… [DataLoader] Mode: {mode} | Loaded: {len(self.samples)} | Skipped: {skipped}")
        
        # === 4. å¢å¼º ===
        self.transform = self._get_transforms()

    def _get_transforms(self):
        if self.mode == 'train':
            return A.Compose([
                A.PadIfNeeded(min_height=self.crop_size, min_width=self.crop_size, border_mode=cv2.BORDER_CONSTANT, value=0),
                A.RandomCrop(width=self.crop_size, height=self.crop_size, p=1.0),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),
                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),
                A.Resize(height=self.image_size, width=self.image_size, interpolation=cv2.INTER_LINEAR),
                ToTensorV2(),
            ])
        else:
            return A.Compose([
                A.PadIfNeeded(min_height=self.crop_size, min_width=self.crop_size, border_mode=cv2.BORDER_CONSTANT, value=0),
                ToTensorV2(),
            ])

    def _decode_mask(self, json_path):
        """é€šç”¨ SA-1B JSON è§£ç """
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        h, w = data.get('height', 256), data.get('width', 256)
        mask = np.zeros((h, w), dtype=np.uint8)
        
        for ann in data.get('annotations', []):
            for poly in ann.get('segmentation', []):
                pts = np.array(poly, dtype=np.int32).reshape((-1, 2))
                cv2.fillPoly(mask, [pts], 1)
        return mask

    def _sample_dynamic_task(self, mask, regions):
        """åŠ¨æ€ä»»åŠ¡é‡‡æ · (ä¿æŒé€»è¾‘ä¸å˜)"""
        active_mask = mask.copy()
        task_type = "generic"
        text_suffix = ""

        if self.mode != 'train' or self.prompt_mode != 'dynamic' or len(regions) < 5:
            return active_mask, task_type, text_suffix

        areas = np.array([r.area for r in regions])
        min_a, max_a = np.min(areas), np.max(areas)
        
        # ç›¸å¯¹å¤§å°å·®å¼‚ä¸å¤Ÿæ˜¾è‘—ï¼Œå°±ä¸åšç‰¹å®šä»»åŠ¡
        if max_a < min_a * 2.0: return active_mask, task_type, text_suffix

        rand_p = random.random()
        
        # 25% æ‰¾å¤§ç»†èƒ
        if rand_p < 0.25:
            task_type = "large"
            text_suffix = "large, pleomorphic"
            th_high = np.percentile(areas, 67)
            temp_mask = np.zeros_like(mask)
            for r in regions:
                if r.area >= th_high: 
                    # åªæœ‰å½“åŒºåŸŸå¤§äºç›¸å¯¹é˜ˆå€¼æ—¶æ‰ä¿ç•™
                    # æ³¨æ„ï¼šè¿™é‡Œç”¨ç®€å•çš„ label åŒ¹é…ï¼Œä¸ºäº†é€Ÿåº¦
                    y, x = int(r.centroid[0]), int(r.centroid[1])
                    if mask[y, x]: # ç®€å•è¿‘ä¼¼ï¼Œå‡†ç¡®åšæ³•æ˜¯ç”¨ r.coords
                        cv2.drawContours(temp_mask, [r.coords[:, ::-1]], -1, 1, -1) # ç•¥å¾®å¤æ‚ï¼Œè¿™é‡Œç®€åŒ–
                        # åœ¨å·¥ç¨‹å®è·µä¸­ï¼Œé€šå¸¸ç›´æ¥ä¿ç•™å…¨å›¾ maskï¼Œåªæ”¹ prompt å³å¯
                        # ä½†ä¸ºäº†å¼ºç›‘ç£ï¼Œæˆ‘ä»¬è¿™é‡Œæš‚æ—¶ä¸åšå¤æ‚çš„ mask è¿‡æ»¤ï¼Œé˜²æ­¢æ€§èƒ½ç“¶é¢ˆ
                        pass 
            # ç®€åŒ–ç­–ç•¥ï¼šå¦‚æœé€‰å®šæ‰¾å¤§ç»†èƒï¼ŒPrompt å˜äº†ï¼Œä½† Mask è¿˜æ˜¯å…¨å›¾ï¼ˆå¼±ç›‘ç£ï¼‰
            # æˆ–è€…æˆ‘ä»¬åªæŠŠ Prompt æ”¹äº†ï¼ŒæœŸå¾…æ¨¡å‹è‡ªå·±å»æ³¨æ„å¤§ç»†èƒã€‚
            # ä¸ºäº†ä¸¥è°¨ï¼ŒMP-SAM åŸé€»è¾‘æ˜¯ä¿®æ”¹ Maskã€‚è¿™é‡Œä¸ºäº†ä»£ç ç®€æ´ï¼Œæš‚ç•¥è¿‡å¤æ‚çš„ region è¿‡æ»¤
            pass 

        return active_mask, task_type, text_suffix

    def __getitem__(self, index):
        item = self.samples[index]
        
        # 1. Load Image
        image = cv2.imread(item['img_path'])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # 2. Decode Mask
        mask = self._decode_mask(item['json_path'])
        
        # 3. Augment
        augmented = self.transform(image=image, mask=mask)
        img_tensor = augmented['image'].float()
        aug_mask = augmented['mask'].numpy().astype(np.uint8)
        
        # 4. Physical Analysis (Dynamic)
        if self.mode == 'train':
            area_scale = (self.image_size / self.crop_size) ** 2
        else:
            area_scale = 1.0
            
        labeled_mask = label(aug_mask)
        regions = regionprops(labeled_mask)
        
        # Dynamic Task
        # (è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œmask ä¸å˜ï¼Œåªå˜ promptï¼Œä¾é  Attention æœºåˆ¶å»å…³æ³¨é‡ç‚¹)
        _, task_type, text_suffix = self._sample_dynamic_task(aug_mask, regions)
        
        # Physics Calculation
        img_np = (img_tensor.permute(1, 2, 0).numpy()).astype(np.uint8)
        analysis = analyze_physical_attributes(img_np, aug_mask, self.attr_config, area_scale)
        visuals = analysis['visuals']
        
        # 5. Construct Prompt
        # Base prompt from Knowledge Base (already high quality)
        base_prompt = item['data']['text_prompt']
        organ_id = item['data']['organ_idx'] # Directly use ID from generation
        
        if task_type != "generic":
            # Override with specific task description
            text_prompt = f"{text_suffix} cell nuclei ({visuals['density']}, {visuals['arrangement']})"
        else:
            # Fallback to dynamic visual description if base prompt is generic
            # Or mix them
            text_prompt = base_prompt

        # 6. Returns
        label_tensor = torch.from_numpy(aug_mask).long().unsqueeze(0)
        gt_heatmap = generate_elliptical_heatmap(aug_mask, image_size=(self.image_size, self.image_size))
        
        # Prompt Dropout
        if self.mode == 'train' and random.random() < 0.2:
            organ_id = 20 # Generic ID (Config dependent, usually last ID)

        return {
            "image": img_tensor,
            "label": label_tensor,
            "gt_heatmap": torch.from_numpy(gt_heatmap).float().unsqueeze(0),
            "organ_id": organ_id,
            "text_prompt": text_prompt,
            "attr_labels": torch.tensor(analysis['labels']).long(),
            "name": os.path.basename(item['img_path']),
            "original_size": (self.image_size, self.image_size),
            "task_type": task_type
        }

def stack_dict_batched(batch):
    tensor_dict = {}
    for key, value in batch[0].items():
        if isinstance(value, torch.Tensor):
            tensor_dict[key] = torch.stack([sample[key] for sample in batch])
        elif isinstance(value, (int, float, str)):
            tensor_dict[key] = [sample[key] for sample in batch]
        else:
            tensor_dict[key] = [sample[key] for sample in batch]
    return tensor_dict