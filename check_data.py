import os
import json
import numpy as np
import glob
import cv2
import math
from tqdm import tqdm

# å°è¯•å¯¼å…¥ pycocotools (å¤„ç† SA-1B RLE æ ¼å¼)
try:
    from pycocotools import mask as coco_mask
except ImportError:
    print("âš ï¸ [Warning] pycocotools not found. RLE decoding might fail.")

def calculate_roundness(area, perimeter):
    """è®¡ç®—åœ†åº¦: 4 * pi * Area / Perimeter^2 (1.0 ä¸ºå®Œç¾Žåœ†)"""
    if perimeter == 0: return 0
    return (4 * np.pi * area) / (perimeter ** 2)

def get_polygon_props(segmentation):
    """ä»Ž Polygon æ ¼å¼èŽ·å–é¢ç§¯å’Œå‘¨é•¿"""
    area = 0
    perimeter = 0
    # SA-1B Polygon æ˜¯ [[x1, y1, x2, y2, ...]]
    for poly in segmentation:
        pts = np.array(poly).reshape(-1, 2).astype(np.float32)
        area += cv2.contourArea(pts)
        perimeter += cv2.arcLength(pts, True)
    return area, perimeter

def get_rle_props(segmentation):
    """ä»Ž RLE æ ¼å¼èŽ·å–é¢ç§¯ (å‘¨é•¿è®¡ç®—è¾ƒå¤æ‚ï¼Œæš‚ç•¥æˆ–ç”¨è¿‘ä¼¼)"""
    if 'counts' in segmentation:
        mask = coco_mask.decode(segmentation)
        area = np.sum(mask)
        # ä»Ž mask æå–è½®å»“ç®—å‘¨é•¿
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        perimeter = 0
        for cnt in contours:
            perimeter += cv2.arcLength(cnt, True)
        return area, perimeter
    return 0, 0

def generate_prompt_library(data_root, output_path="data/MoNuSeg_SA1B/specific_prompts.json"):
    print(f"ðŸš€ Scanning dataset in: {data_root}")
    
    json_files = glob.glob(os.path.join(data_root, "**/*.json"), recursive=True)
    # è¿‡æ»¤æŽ‰éžæ ‡æ³¨æ–‡ä»¶ (æ¯”å¦‚æˆ‘ä»¬è‡ªå·±ç”Ÿæˆçš„ stats.json)
    json_files = [f for f in json_files if "attributes" not in f and "prompts" not in f and "stats" not in f]
    
    print(f"ðŸ“‚ Found {len(json_files)} annotation files.")

    # === ç¬¬ä¸€æ­¥ï¼šå…¨å±€ç»Ÿè®¡ (Global Statistics) ===
    print("\n[Step 1] Analyzing Global Statistics (PromptNu Method)...")
    
    all_areas = []
    all_roundness = []
    img_counts = []
    
    # æš‚å­˜æ¯å¼ å›¾çš„åŽŸå§‹æ•°æ®ï¼Œé¿å…è¯»ä¸¤æ¬¡æ–‡ä»¶
    img_cache = {} 

    for json_file in tqdm(json_files):
        filename = os.path.basename(json_file).replace(".json", "")
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
            
            anns = data.get('annotations', []) if isinstance(data, dict) else data
            
            img_areas = []
            img_roundness = []
            
            for ann in anns:
                area, perimeter = 0, 0
                
                # 1. ä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—çš„ area
                if 'area' in ann:
                    area = ann['area']
                
                # 2. å¦‚æžœæ²¡æœ‰ï¼Œæˆ–è€…éœ€è¦ç®—å‘¨é•¿ï¼Œåˆ™è§£ç  Segmentation
                if 'segmentation' in ann:
                    seg = ann['segmentation']
                    if isinstance(seg, list): # Polygon
                        a, p = get_polygon_props(seg)
                        if area == 0: area = a
                        perimeter = p
                    elif isinstance(seg, dict): # RLE
                        a, p = get_rle_props(seg)
                        if area == 0: area = a
                        perimeter = p
                
                if area > 10: # å¿½ç•¥æžå°å™ªç‚¹
                    img_areas.append(area)
                    all_areas.append(area)
                    if perimeter > 0:
                        r = calculate_roundness(area, perimeter)
                        img_roundness.append(r)
                        all_roundness.append(r)

            count = len(img_areas)
            img_counts.append(count)
            
            img_cache[filename] = {
                "areas": img_areas,
                "roundness": img_roundness,
                "count": count
            }
            
        except Exception as e:
            print(f"âŒ Error reading {json_file}: {e}")

    # === è®¡ç®— PromptNu é˜ˆå€¼ ===
    # è®ºæ–‡ III.B: Mean å’Œ Mean + 2*Std
    np_areas = np.array(all_areas)
    np_counts = np.array(img_counts)
    np_round = np.array(all_roundness)

    mean_area = np.mean(np_areas)
    std_area = np.std(np_areas)
    
    mean_count = np.mean(np_counts)
    std_count = np.std(np_counts)
    
    mean_round = np.mean(np_round)

    print("\nðŸ“Š Dataset Statistics:")
    print(f"  Nuclei Size (Area): Mean={mean_area:.1f}, Std={std_area:.1f}")
    print(f"  Nuclei Count/Img:   Mean={mean_count:.1f}, Std={std_count:.1f}")
    print(f"  Roundness:          Mean={mean_round:.2f}")

    # å®šä¹‰é˜ˆå€¼ (Thresholds)
    THRESHOLDS = {
        "size": {
            "small_limit": mean_area, # å°äºŽå‡å€¼ = Small
            "large_limit": mean_area + std_area # å¤§äºŽå‡å€¼+1å€æ–¹å·® = Large (è®ºæ–‡æ˜¯2å€ï¼Œä½†ç—…ç†å›¾é€šå¸¸1å€æ›´åˆç†ï¼Œå¯è°ƒ)
        },
        "density": {
            "sparse_limit": max(1, mean_count - std_count),
            "dense_limit": mean_count + std_count
        },
        "shape": {
            "round_limit": 0.85, # åœ†åº¦ > 0.85 ç®—åœ†
            "irregular_limit": 0.60 # åœ†åº¦ < 0.60 ç®—ä¸è§„åˆ™
        }
    }
    
    print(f"âš™ï¸  Thresholds: Large > {THRESHOLDS['size']['large_limit']:.1f}, Dense > {THRESHOLDS['density']['dense_limit']:.1f}")

    # === ç¬¬äºŒæ­¥ï¼šç”Ÿæˆä¸“ç”¨æ–‡æœ¬ (Prompt Generation) ===
    print("\n[Step 2] Generating Specific Prompts...")
    
    prompt_library = {}
    
    for filename, stats in img_cache.items():
        if stats["count"] == 0: continue
        
        # 1. Size Attribute
        avg_area = np.mean(stats["areas"])
        if avg_area > THRESHOLDS["size"]["large_limit"]:
            size_desc = "large"
        elif avg_area < THRESHOLDS["size"]["small_limit"]:
            size_desc = "small"
        else:
            size_desc = "medium"
            
        # 2. Density Attribute
        cnt = stats["count"]
        if cnt > THRESHOLDS["density"]["dense_limit"]:
            density_desc = "densely packed"
        elif cnt < THRESHOLDS["density"]["sparse_limit"]:
            density_desc = "sparsely distributed"
        else:
            density_desc = "moderately distributed"
            
        # 3. Shape Attribute
        avg_rnd = np.mean(stats["roundness"]) if stats["roundness"] else 0
        if avg_rnd > THRESHOLDS["shape"]["round_limit"]:
            shape_desc = "round"
        elif avg_rnd < THRESHOLDS["shape"]["irregular_limit"]:
            shape_desc = "irregular"
        else:
            shape_desc = "elliptical"

        # === æ ¸å¿ƒï¼šPromptNu é£Žæ ¼çš„å¥å­æž„å»º ===
        # Template: "Microscopic image of [Size], [Shape] nuclei, [Density]."
        specific_prompt = f"Microscopic image of {size_desc}, {shape_desc} nuclei, {density_desc}."
        
        prompt_library[filename] = {
            "prompt": specific_prompt,
            "attributes": {
                "size": size_desc,
                "shape": shape_desc,
                "density": density_desc
            },
            "stats": {
                "avg_area": float(avg_area),
                "count": int(cnt),
                "avg_roundness": float(avg_rnd)
            }
        }

    # ä¿å­˜ç»“æžœ
    with open(output_path, 'w') as f:
        json.dump(prompt_library, f, indent=4)
        
    print(f"\nâœ… Generated Specific Prompts for {len(prompt_library)} images.")
    print(f"ðŸ’¾ Saved to: {output_path}")
    print(f"ðŸ“ Example: {list(prompt_library.values())[0]['prompt']}")

if __name__ == "__main__":
    # ðŸ”¥ ä¿®æ”¹ä¸ºä½ çš„æ•°æ®è·¯å¾„
    DATA_PATH = "data/MoNuSeg_SA1B" 
    generate_prompt_library(DATA_PATH)