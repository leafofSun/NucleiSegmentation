import os
import json
import glob
import numpy as np
import cv2
from tqdm import tqdm
from skimage import measure

# ==============================================================================
# âš™ï¸ é…ç½®åŒºåŸŸ (Configuration)
# ==============================================================================
# è¯·ç¡®ä¿è¿™é‡ŒæŒ‡å‘æ‚¨å­˜æ”¾ .json æ–‡ä»¶çš„ç›®å½• (ä¾‹å¦‚ MoNuSeg çš„ Training æˆ– Test ç›®å½•)
DATA_ROOT = "data/MoNuSeg_SA1B/train" 
OUTPUT_JSON = "data/MoNuSeg_SA1B/medical_knowledge.json"

# ==============================================================================
# ğŸ§  åŒ»å­¦çŸ¥è¯†æ˜ å°„ (Medical Knowledge Mappings)
# ==============================================================================

# 1. MoNuSeg ç²¾ç¡®å™¨å®˜æ˜ å°„ (TCGA Mapping)
TCGA_MAP = {
    # --- Training Set ---
    "TCGA-B0": "Kidney", "TCGA-HE": "Kidney", "TCGA-2Z": "Kidney", 
    "TCGA-A7": "Breast", "TCGA-AR": "Breast", "TCGA-E2": "Breast", "TCGA-AO": "Breast",
    "TCGA-G9": "Prostate", "TCGA-CH": "Prostate", "TCGA-EJ": "Prostate",
    "TCGA-18": "Lung", "TCGA-38": "Lung", "TCGA-49": "Lung", "TCGA-50": "Lung", "TCGA-21": "Lung",
    "TCGA-A6": "Colon", "TCGA-CM": "Colon", "TCGA-NH": "Colon", 
    # --- Test Set ---
    "TCGA-AY": "Stomach", "TCGA-KB": "Stomach", "TCGA-RD": "Stomach",
    "TCGA-IZ": "Liver", "TCGA-MH": "Liver",
    "TCGA-DK": "Bladder", "TCGA-ZF": "Bladder",
    "TCGA-HT": "Brain", "TCGA-CS": "Brain",
}

# 2. æ˜¾å¼ç—…ç†å…ˆéªŒåº“
ORGAN_KNOWLEDGE = {
    "Kidney": {"context": "Renal tissue", "cell_desc": "Epithelial cells of proximal tubules", "structure": "tubular structure"},
    "Breast": {"context": "Mammary tissue", "cell_desc": "Ductal epithelial cells", "structure": "ductal lobular units"},
    "Prostate": {"context": "Prostatic tissue", "cell_desc": "Glandular epithelial cells", "structure": "acinar glands"},
    "Lung": {"context": "Pulmonary tissue", "cell_desc": "Pneumocytes and macrophages", "structure": "alveolar architecture"},
    "Colon": {"context": "Colonic mucosa", "cell_desc": "Columnar epithelial cells", "structure": "glandular crypts"},
    "Stomach": {"context": "Gastric mucosa", "cell_desc": "Glandular cells", "structure": "gastric pits"},
    "Liver": {"context": "Hepatic tissue", "cell_desc": "Hepatocytes", "structure": "hepatic cords"},
    "Bladder": {"context": "Urothelial tissue", "cell_desc": "Transitional epithelial cells", "structure": "urothelium layers"},
    "Brain": {"context": "Brain tissue", "cell_desc": "Glial cells and neurons", "structure": "neuropil background"},
    "Generic": {"context": "Histopathology tissue", "cell_desc": "Nuclei", "structure": "cellular region"}
}

def get_organ_from_filename(filename):
    """æ ¹æ®æ–‡ä»¶åè§£æå™¨å®˜ç±»å‹"""
    for code, organ in TCGA_MAP.items():
        if code in filename: return organ
    for organ in ORGAN_KNOWLEDGE.keys():
        if organ.lower() in filename.lower(): return organ
    return "Generic"

# ==============================================================================
# ğŸ› ï¸ æ ¸å¿ƒå·¥å…·å‡½æ•° (Core Utilities)
# ==============================================================================

def decode_instance_mask_from_json(json_path, shape_hint=(1000, 1000)):
    """
    ğŸ”¥ [æ ¸å¿ƒä¿®å¤] ç”Ÿæˆ Instance Mask (int32)ï¼Œæ¯ä¸ªç»†èƒä¸€ä¸ªç‹¬ç«‹ IDã€‚
    è§£å†³æ—§ç‰ˆ 'Binary Mask' å¯¼è‡´çš„ç»†èƒç²˜è¿ã€æ ‡å‡†å·®çˆ†ç‚¸é—®é¢˜ã€‚
    """
    try:
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        h, w = shape_hint
        if "image" in data:
            h = data["image"].get("height", h)
            w = data["image"].get("width", w)

        # ä½¿ç”¨ int32 å­˜å‚¨ ID (æ”¯æŒ >255 ä¸ªç»†èƒ)
        instance_mask = np.zeros((h, w), dtype=np.int32)
        anns = data.get('annotations', [])
        
        # å°è¯•ä½¿ç”¨ pycocotools åŠ é€Ÿ RLE è§£ç 
        try:
            import pycocotools.mask as coco_mask
            has_coco = True
        except ImportError:
            has_coco = False

        current_id = 1 
        
        for ann in anns:
            if 'segmentation' not in ann: continue
            seg = ann['segmentation']
            
            single_obj_mask = None
            
            if isinstance(seg, dict) and has_coco: # RLE æ ¼å¼
                single_obj_mask = coco_mask.decode(seg)
            elif isinstance(seg, list): # Polygon æ ¼å¼
                temp_mask = np.zeros((h, w), dtype=np.uint8)
                for poly in seg:
                    # æ³¨æ„ï¼šåæ ‡å¯èƒ½éœ€è¦å–æ•´
                    pts = np.array(poly).reshape(-1, 2).astype(np.int32)
                    cv2.fillPoly(temp_mask, [pts], 1)
                single_obj_mask = temp_mask

            # å°†å½“å‰ç»†èƒä»¥ Unique ID å¡«å…¥ä¸» Mask
            if single_obj_mask is not None:
                # å³ä½¿åƒç´ é‡å ï¼Œä¹Ÿä¼šè¦†ç›–ä¸ºæ–°çš„ IDï¼Œä»è€Œåœ¨é€»è¾‘ä¸Šåˆ†ç¦»å®ƒä»¬
                instance_mask[single_obj_mask > 0] = current_id
                current_id += 1
                
        return instance_mask
    except Exception as e:
        # print(f"Error decoding {json_path}: {e}")
        return np.zeros(shape_hint, dtype=np.int32)

def get_dataset_statistics(json_files):
    """
    ğŸ”¥ [Pass 1] å…¨å±€æ‰«æï¼šè®¡ç®—åˆ†ä½æ•°ç»Ÿè®¡ (Percentiles)ã€‚
    ç›¸æ¯” Mean/Stdï¼Œåˆ†ä½æ•°å¯¹é•¿å°¾åˆ†å¸ƒå’Œå‰©ä½™çš„ç²˜è¿å™ªå£°æ›´é²æ£’ã€‚
    """
    print("ğŸ“Š Phase 1: Analyzing dataset statistics (Global Pass - Instance Level)...")
    
    all_areas = []
    nuclei_counts = []
    
    for json_path in tqdm(json_files):
        # ä½¿ç”¨å®ä¾‹æ©ç è§£ç ï¼
        instance_mask = decode_instance_mask_from_json(json_path)
        
        # å¦‚æœ Mask ä¸ºç©ºï¼Œè·³è¿‡
        if instance_mask.max() == 0: continue
            
        # measure.regionprops å¯ä»¥æ­£ç¡®åŒºåˆ†ä¸åŒçš„ ID
        props = measure.regionprops(instance_mask)
        
        nuclei_counts.append(len(props))
        for p in props:
            # å®‰å…¨è¿‡æ»¤ï¼šå¿½ç•¥ >10000 åƒç´ çš„æç«¯å¼‚å¸¸å€¼ï¼ˆå¯èƒ½æ˜¯æ ‡æ³¨é”™è¯¯ï¼‰
            if p.area < 10000:
                all_areas.append(p.area)
            
    all_areas = np.array(all_areas)
    nuclei_counts = np.array(nuclei_counts)
    
    if len(all_areas) == 0:
        return None

    # ä½¿ç”¨åˆ†ä½æ•°å®šä¹‰é˜ˆå€¼
    # Small: æœ€å°çš„ 33%
    # Large: æœ€å¤§çš„ 33% (Top 33%)
    stats = {
        "size_th_small": np.percentile(all_areas, 33),
        "size_th_large": np.percentile(all_areas, 67),
        
        "dense_th_sparse": np.percentile(nuclei_counts, 33),
        "dense_th_dense": np.percentile(nuclei_counts, 67),

        # ä»…ä¾›å‚è€ƒçš„å‡å€¼
        "size_mean": np.mean(all_areas)
    }
    
    print(f"\nğŸ“ˆ Robust Statistics Report (Percentiles):")
    print(f"   [Size] Mean: {stats['size_mean']:.1f} px (Instance-based)")
    print(f"   [Size Thresholds] Small < {stats['size_th_small']:.1f} | Large > {stats['size_th_large']:.1f}")
    print(f"   [Density Thresholds] Sparse < {stats['dense_th_sparse']:.1f} | Dense > {stats['dense_th_dense']:.1f}\n")
    
    return stats

def analyze_visuals_dynamic(mask, stats):
    """
    ğŸ”¥ [Pass 2] åŠ¨æ€åˆ¤å®šï¼šæ ¹æ®å…¨å±€é˜ˆå€¼åˆ¤å®šå½“å‰å›¾ç‰‡çš„å±æ€§
    """
    # mask å¿…é¡»æ˜¯ Instance Mask
    if mask.max() == 0 or stats is None:
        return {"size": "medium-sized", "shape": "round", "density": "moderate"}
        
    props = measure.regionprops(mask)
    if not props: 
        return {"size": "medium-sized", "shape": "round", "density": "moderate"}
    
    # 1. Size (å¯¹æ¯”å…¨å±€é˜ˆå€¼)
    current_mean_area = np.mean([p.area for p in props])
    
    if current_mean_area > stats['size_th_large']:
        size_desc = "large, enlarged"
    elif current_mean_area < stats['size_th_small']:
        size_desc = "small"
    else:
        size_desc = "medium-sized"
    
    # 2. Density (å¯¹æ¯”å…¨å±€é˜ˆå€¼)
    count = len(props)
    if count > stats['dense_th_dense']:
        density_desc = "densely packed"
    elif count < stats['dense_th_sparse']:
        density_desc = "sparsely distributed"
    else:
        density_desc = "moderately distributed"
        
    # 3. Shape (ä½¿ç”¨åå¿ƒç‡è¿‘ä¼¼å½¢çŠ¶)
    mean_ecc = np.mean([p.eccentricity for p in props])
    if mean_ecc > 0.8: shape_desc = "elongated, spindle-shaped"
    elif mean_ecc < 0.6: shape_desc = "round, spherical"
    else: shape_desc = "oval"
    
    return {"size": size_desc, "shape": shape_desc, "density": density_desc}

def construct_text_prompt(organ, visuals):
    """æ„å»ºæœ€ç»ˆçš„æ–‡æœ¬æç¤ºï¼Œèåˆè¯­ä¹‰ä¸è§†è§‰ç‰¹å¾"""
    kb = ORGAN_KNOWLEDGE.get(organ, ORGAN_KNOWLEDGE["Generic"])
    cell_desc = kb['cell_desc']
    adj = ""
    
    # è§„åˆ™ 1: æ¶æ€§è‚¿ç˜¤ç‰¹å¾
    if organ in ["Breast", "Kidney", "Lung", "Colon"] and "enlarged" in visuals['size']:
        cell_desc = "Pleomorphic Tumor Nuclei"
        adj = "hyperchromatic"
    # è§„åˆ™ 2: æ·‹å·´ç»†èƒç‰¹å¾
    elif "small" in visuals['size'] and "round" in visuals['shape']:
        cell_desc = "Lymphocytes"
        adj = "darkly stained"
    # è§„åˆ™ 3: è…ºä½“ç‰¹å¾
    elif organ in ["Prostate", "Colon"] and "dense" in visuals['density']:
        cell_desc = "Glandular Epithelial Nuclei"
        adj = "basally oriented"

    text = (f"Microscopic view of {adj} {visuals['size']} {cell_desc} with {visuals['shape']} features, "
            f"{visuals['density']} in {kb['context']} featuring {kb['structure']}.")
    
    return " ".join(text.split())

# ==============================================================================
# ğŸš€ ä¸»ç¨‹åº (Main Execution)
# ==============================================================================
def main():
    # 1. æ‰«ææ–‡ä»¶
    json_files = glob.glob(os.path.join(DATA_ROOT, "*.json"))
    # æ’é™¤éæ•°æ® json
    json_files = [f for f in json_files if "knowledge" not in f and "attribute" not in f]
    
    if not json_files:
        print(f"âŒ No .json files found in {DATA_ROOT}")
        return

    # 2. ç¬¬ä¸€éæ‰«æ: è·å–å…¨å±€ç»Ÿè®¡ä¿¡æ¯ (Pass 1)
    dataset_stats = get_dataset_statistics(json_files)
    
    print(f"ğŸš€ Phase 2: Generating Knowledge Base...")
    kb_database = {}
    
    # 3. ç¬¬äºŒéæ‰«æ: ç”Ÿæˆå…·ä½“æè¿° (Pass 2)
    for json_path in tqdm(json_files):
        filename = os.path.basename(json_path).replace(".json", ".tif")
        organ = get_organ_from_filename(filename)
        
        # âš ï¸ å¿…é¡»ä½¿ç”¨ decode_instance_mask_from_json ä»¥ä¿æŒé€»è¾‘ä¸€è‡´
        instance_mask = decode_instance_mask_from_json(json_path)
        
        visuals = analyze_visuals_dynamic(instance_mask, dataset_stats)
        prompt = construct_text_prompt(organ, visuals)
        
        kb_database[filename] = {
            "organ_id": organ,
            "text_prompt": prompt,
            "visual_stats": visuals
        }
        
    # 4. ä¿å­˜ç»“æœ
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(OUTPUT_JSON), exist_ok=True)
    
    with open(OUTPUT_JSON, 'w') as f:
        json.dump(kb_database, f, indent=4)
        
    print(f"âœ… Knowledge Base saved to: {OUTPUT_JSON}")
    print("   Ready for data-driven training!")

if __name__ == "__main__":
    main()