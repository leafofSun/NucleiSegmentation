import os
import json
import cv2
import numpy as np
import glob
from tqdm import tqdm
from skimage import measure

# å°è¯•å¯¼å…¥ pycocotoolsï¼Œè¿™æ˜¯è§£æ SA-1B RLE çš„æ ‡å‡†å·¥å…·
try:
    from pycocotools import mask as coco_mask
except ImportError:
    print("âš ï¸ è¯·å®‰è£… pycocotools: pip install pycocotools")
    exit()

# === é…ç½®è·¯å¾„ ===
# æŒ‡å‘åŒ…å«å›¾ç‰‡å’Œå¯¹åº” json çš„æ–‡ä»¶å¤¹
DATA_ROOT = "data/MoNuSeg_SA1B/train" 
OUTPUT_JSON = "data/MoNuSeg_SA1B/attribute_info_train.json"

def decode_sa1b_mask(json_path, shape=None):
    """
    ä» SA-1B æ ¼å¼çš„ JSON ä¸­è§£æå‡ºäºŒå€¼ Mask
    """
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    # SA-1B æ ‡æ³¨é€šå¸¸åœ¨ 'annotations' åˆ—è¡¨é‡Œ
    anns = data.get('annotations', [])
    if not anns and isinstance(data, list): anns = data # å…¼å®¹ç›´æ¥æ˜¯ list çš„æƒ…å†µ
    
    # å¦‚æœä¸çŸ¥é“å›¾åƒå°ºå¯¸ï¼Œå°è¯•ä» json æˆ–ç¬¬ä¸€æ¡æ ‡æ³¨æ¨æ–­ï¼Œæˆ–è€…ç”±å¤–éƒ¨ä¼ å…¥
    # è¿™é‡Œæˆ‘ä»¬å»ºç«‹ä¸€ä¸ªå…¨é»‘åº•å›¾
    if shape is None:
        # å°è¯•è¯»å–åŒåå›¾ç‰‡è·å–å°ºå¯¸
        img_path = json_path.replace(".json", ".tif") 
        if not os.path.exists(img_path):
             img_path = json_path.replace(".json", ".png")
        if os.path.exists(img_path):
            temp_img = cv2.imread(img_path)
            h, w = temp_img.shape[:2]
        else:
            # å…œåº•ï¼šå¦‚æœæ‰¾ä¸åˆ°å›¾ï¼Œé»˜è®¤ 1000x1000 (MoNuSegæ ‡å‡†)
            h, w = 1000, 1000
    else:
        h, w = shape

    full_mask = np.zeros((h, w), dtype=np.uint8)

    for ann in anns:
        if 'segmentation' in ann:
            seg = ann['segmentation']
            # æƒ…å†µ A: RLE æ ¼å¼ (SA-1B æ ‡å‡†)
            if isinstance(seg, dict) and 'counts' in seg:
                rle_mask = coco_mask.decode(seg)
                full_mask[rle_mask > 0] = 1
            # æƒ…å†µ B: Polygon æ ¼å¼ (ç‚¹åˆ—è¡¨)
            elif isinstance(seg, list):
                for poly in seg:
                    pts = np.array(poly, dtype=np.int32).reshape((-1, 2))
                    cv2.fillPoly(full_mask, [pts], 1)
    
    return full_mask

def analyze_mask(mask):
    """
    å¯¹ Mask è¿›è¡Œè¿é€šåŸŸåˆ†æï¼Œæå– PromptNu æ‰€éœ€çš„ 5 å¤§å±æ€§
    """
    # è¿é€šåŸŸæ ‡è®°
    labels = measure.label(mask)
    props = measure.regionprops(labels)
    
    if len(props) == 0:
        return None

    # --- 1. Size (å¤§å°) ---
    areas = [p.area for p in props]
    mean_area = np.mean(areas)
    
    size_tags = []
    # é˜ˆå€¼å¯å¾®è°ƒ
    if mean_area < 250: size_tags.append("small")
    elif mean_area < 650: size_tags.append("medium")
    else: size_tags.append("large")
        
    # --- 2. Density (å¯†åº¦) ---
    h, w = mask.shape
    foreground_ratio = np.sum(mask) / (h * w)
    count = len(props)
    
    density_tags = []
    if foreground_ratio > 0.20 or count > 400:
        density_tags.append("densely packed")
    elif foreground_ratio > 0.05 or count > 100:
        density_tags.append("moderately dense")
    else:
        density_tags.append("sparsely distributed")

    # --- 3. Shape (å½¢çŠ¶) ---
    eccentricities = [p.eccentricity for p in props]
    mean_ecc = np.mean(eccentricities)
    
    shape_tags = []
    if mean_ecc > 0.85:
        shape_tags.extend(["elongated", "spindle-shaped"])
    elif mean_ecc < 0.5:
        shape_tags.extend(["round", "spherical"])
    else:
        shape_tags.append("elliptical/oval")
        
    solidities = [p.solidity for p in props]
    if np.mean(solidities) < 0.85:
        shape_tags.append("irregular")

    # --- 4. Arrange (æ’åˆ—) ---
    arrange_tags = ["scattered"]
    if "densely packed" in density_tags:
        arrange_tags.append("clustered")
        
    # --- 5. Color (é¢œè‰²) ---
    color_tags = ["deep purple"] # H&E å›ºå®š

    # === æ„é€  Rich Text ===
    # ç±»ä¼¼äº: "Deep purple small elliptical/oval nuclei, densely packed"
    rich_text = f"{color_tags[0]} {size_tags[0]} "
    if len(shape_tags) > 0: rich_text += f"{shape_tags[0]} "
    rich_text += "nuclei"
    if "densely packed" in density_tags: rich_text += ", densely packed"
    elif "sparsely distributed" in density_tags: rich_text += ", scattered"

    return {
        "color": list(set(color_tags)),
        "size": list(set(size_tags)),
        "density": list(set(density_tags)),
        "arrange": list(set(arrange_tags)),
        "shape": list(set(shape_tags)),
        "rich_text": rich_text,
        "target_text": rich_text # å…¼å®¹æ—§ä»£ç  Key
    }

def main():
    # æ‰«ææ‰€æœ‰ .json æ–‡ä»¶ (æ’é™¤æ‰æˆ‘ä»¬è‡ªå·±ç”Ÿæˆçš„ attribute json)
    json_files = glob.glob(os.path.join(DATA_ROOT, "**", "*.json"), recursive=True)
    
    # è¿‡æ»¤æ‰é GT çš„ json (æ¯”å¦‚ç”Ÿæˆçš„ prompt json)
    json_files = [f for f in json_files if "attribute_info" not in f and "global_label" not in f]
    
    print(f"ğŸ” Found {len(json_files)} SA-1B JSON files. Analyzing...")
    
    prompt_dict = {} # ç”¨äºä¿å­˜ç»“æœçš„å­—å…¸
    
    for json_path in tqdm(json_files):
        filename = os.path.basename(json_path)
        # å‡è®¾å›¾ç‰‡åå’Œjsonåä¸€è‡´ (e.g., img.tif, img.json)
        # æˆ–è€…æ˜¯ img.tif å¯¹åº” img.json
        # æˆ‘ä»¬ç”¨å›¾ç‰‡æ–‡ä»¶åä½œä¸º Key
        img_name = filename.replace(".json", ".tif") 
        # å¦‚æœæ‚¨çš„æ•°æ®é›†ä¸­æ˜¯ .pngï¼Œè¯·æ”¹ä¸º .png
        if not os.path.exists(os.path.join(os.path.dirname(json_path), img_name)):
             img_name = filename.replace(".json", ".png")

        # 1. è§£ç  Mask
        try:
            mask = decode_sa1b_mask(json_path)
        except Exception as e:
            print(f"âŒ Error decoding {filename}: {e}")
            continue
            
        # 2. åˆ†æå±æ€§
        if np.sum(mask) == 0:
            continue # ç©º Mask è·³è¿‡
            
        attrs = analyze_mask(mask)
        
        # 3. è®°å½•
        # æ·»åŠ  PromptNu é£æ ¼çš„ attribute_prompts å­—æ®µ
        all_prompts = []
        for k in ["color", "size", "shape", "density", "arrange"]:
            all_prompts.extend(attrs[k])
        attrs["attribute_prompts"] = all_prompts
        
        # ä»¥å›¾ç‰‡æ–‡ä»¶å (xxx.tif) ä¸º Key
        prompt_dict[img_name] = attrs

    # ä¿å­˜ä¸º Dict æ ¼å¼ (ä¾› DataLoader ä½¿ç”¨)
    with open(OUTPUT_JSON, 'w') as f:
        json.dump(prompt_dict, f, indent=4)
        
    print(f"âœ… Saved attributes to {OUTPUT_JSON}")
    print(f"   Total processed: {len(prompt_dict)}")

if __name__ == "__main__":
    main()